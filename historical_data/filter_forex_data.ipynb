{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from ib_insync import *\n",
    "import pandas as pd\n",
    "import datetime \n",
    "from functools import reduce\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "forex_path = 'Forex/'\n",
    "currencies = [\"AUD_USD_minute_\", \"USD_HKD_minute_\", \"USD_JPY_minute_\"]\n",
    "currency_times = [(\"19:00:00\", \"20:00:00\"), (\"20:30:00\", \"21:30:00\"), (\"19:00:00\", \"20:00:00\")]\n",
    "new_csv_names = [\"AUD_USD_new.csv\", \"USD_HKD_new.csv\", \"USD_JPY_new.csv\"]\n",
    "ir = pd.read_csv(\"../market_metadata/interest_rates.csv\")\n",
    "ir_list = [ir[[\"Date\", \"rates_Aus\"]].copy(), ir[[\"Date\", \"rates_HK\"]].copy(), ir[[\"Date\", \"rates_Japan\"]].copy()]\n",
    "for df in ir_list:\n",
    "    df.columns = [\"date\", \"ir\"]\n",
    "ir_list[1].loc[439,\"ir\"] = 1\n",
    "ir_list[1].loc[804,\"ir\"] = 1.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 3134 rows of US market open data\n",
      "We have 3130 rows of non-US market open data\n",
      "There are 1567 and 1567 rows of US market data before and at market open respectively.\n",
      "There are 1565 and 1565 rows of non-US market data before and at market open respectively.\n",
      "We have 3134 rows of US market open data\n",
      "We have 3128 rows of non-US market open data\n",
      "There are 1567 and 1567 rows of US market data before and at market open respectively.\n",
      "There are 1564 and 1564 rows of non-US market data before and at market open respectively.\n",
      "We have 3130 rows of US market open data\n",
      "We have 3128 rows of non-US market open data\n",
      "There are 1565 and 1565 rows of US market data before and at market open respectively.\n",
      "There are 1564 and 1564 rows of non-US market data before and at market open respectively.\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    # Collect all data in one df\n",
    "    filenames = sorted([f for f in listdir(forex_path) if currencies[i] in f])\n",
    "    df = pd.DataFrame(columns = [\"date\", \"avg_bid\", \"avg_ask\"])\n",
    "    for filename in filenames:\n",
    "        new_df = pd.read_csv(forex_path + filename, index_col = 0).rename(columns = {'close':'avg_ask', 'open':'avg_bid'})[[\"date\", 'avg_bid', \"avg_ask\"]]\n",
    "        df = pd.concat([df, new_df])\n",
    "        \n",
    "    # Filter for correct data\n",
    "    df = df[(df[\"date\"] > \"2015-04\")] \n",
    "    df = df.drop_duplicates()\n",
    "    df = df.reset_index(drop = True)\n",
    "    \n",
    "    # Filter into US/Non-US\n",
    "    us_df = df[df[\"date\"].str.endswith(\"09:30:00\") | df[\"date\"].str.endswith(\"09:29:00\")].copy()\n",
    "    indices = df[\"date\"].str.endswith(currency_times[i][0]) | df[\"date\"].str.endswith(currency_times[i][1])\n",
    "    prev_indices = indices.shift(-1)\n",
    "    prev_indices[len(prev_indices)-1] = False\n",
    "    non_us_df = df[indices | prev_indices].copy()\n",
    "    print(\"We have {} rows of US market open data\".format(len(us_df)))\n",
    "    print(\"We have {} rows of non-US market open data\".format(len(non_us_df)))\n",
    "    \n",
    "    # Convert Asian market opens into local date\n",
    "    for j in range(len(non_us_df)):\n",
    "        if j % 2 == 1:\n",
    "            date_str = non_us_df.iloc[j,0]\n",
    "            day_str, time_str = tuple(date_str.split())\n",
    "            day = datetime.datetime.strptime(day_str, '%Y-%m-%d')\n",
    "            day += datetime.timedelta(days=1)\n",
    "            new_day = day.strftime('%Y-%m-%d')\n",
    "            non_us_df.iloc[j,0] = new_day + \" \" + time_str\n",
    "            date_str = non_us_df.iloc[j-1,0]\n",
    "            day_str, time_str = tuple(date_str.split())\n",
    "            non_us_df.iloc[j-1,0] = new_day + \" \" + time_str\n",
    "            \n",
    "    # Split datasets, merge into one, save\n",
    "    us_df_before = us_df[us_df[\"date\"].str.endswith(\"9:00\")].copy()\n",
    "    us_df_at = us_df[us_df[\"date\"].str.endswith(\"0:00\")].copy()\n",
    "    # Check\n",
    "    print(\"There are {} and {} rows of US market data before and at market open respectively.\".format(len(us_df_before), len(us_df_at)))\n",
    "\n",
    "    non_us_df_before = non_us_df[non_us_df[\"date\"].str.endswith(\"9:00\")].copy()\n",
    "    non_us_df_at = non_us_df[non_us_df[\"date\"].str.endswith(\"0:00\")].copy()\n",
    "    # Check\n",
    "    print(\"There are {} and {} rows of non-US market data before and at market open respectively.\".format(len(non_us_df_before), len(non_us_df_at)))\n",
    "\n",
    "    non_us_df_before.rename(columns = {'avg_bid':'avg_bid_non_us_before', 'avg_ask':'avg_ask_non_us_before'}, inplace = True)\n",
    "    non_us_df_before[\"avg_non_us_before\"] = (non_us_df_before[\"avg_bid_non_us_before\"] + non_us_df_before[\"avg_ask_non_us_before\"])/2\n",
    "    non_us_df_before[\"date\"] = non_us_df_before[\"date\"].str.split().str[0]\n",
    "    non_us_df_at.rename(columns = {'avg_bid':'avg_bid_non_us_at', 'avg_ask':'avg_ask_non_us_at'}, inplace = True)\n",
    "    non_us_df_at[\"avg_non_us_at\"] = (non_us_df_at[\"avg_bid_non_us_at\"] + non_us_df_at[\"avg_ask_non_us_at\"])/2\n",
    "    non_us_df_at[\"date\"] = non_us_df_at[\"date\"].str.split().str[0]\n",
    "    us_df_before.rename(columns = {'avg_bid':'avg_bid_us_before', 'avg_ask':'avg_ask_us_before'}, inplace = True)\n",
    "    us_df_before[\"avg_us_before\"] = (us_df_before[\"avg_bid_us_before\"] + us_df_before[\"avg_ask_us_before\"])/2\n",
    "    us_df_before[\"date\"] = us_df_before[\"date\"].str.split().str[0]\n",
    "    us_df_at.rename(columns = {'avg_bid':'avg_bid_us_at', 'avg_ask':'avg_ask_us_at'}, inplace = True)\n",
    "    us_df_at[\"avg_us_at\"] = (us_df_at[\"avg_bid_us_at\"] + us_df_at[\"avg_ask_us_at\"])/2\n",
    "    us_df_at[\"date\"] = us_df_at[\"date\"].str.split().str[0]\n",
    "    final_df = reduce(lambda x, y : pd.merge(x, y), [non_us_df_before, non_us_df_at, us_df_before, us_df_at])\n",
    "    final_df = pd.merge(final_df, ir_list[i], \"left\")\n",
    "    final_df.to_csv(forex_path + new_csv_names[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are small discrepancies between US and non-US data, due to holidays in the Asian markets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IB connected to 127.0.0.1:7497 clientId=15>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ib_insync import *\n",
    "util.startLoop()\n",
    "\n",
    "ib = IB()\n",
    "ib.connect('127.0.0.1', 7497, clientId=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ib_insync import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import datetime \n",
    "import statsmodels.formula.api as smf \n",
    "from datetime import date, time, datetime, timedelta\n",
    "import seaborn as sns\n",
    "import random\n",
    "from ta import add_all_ta_features\n",
    "from ta.utils import dropna\n",
    "from ta.trend import *\n",
    "from collections import deque, defaultdict\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initialization of hard coded data ###\n",
    "\n",
    "order_books = defaultdict(set)\n",
    "df_ratio = pd.read_csv(\"ratio_dict.csv\", index_col = 0).set_index(\"Pair\")\n",
    "df_global = pd.DataFrame({\"date\":[]})\n",
    "df_num_adr_per_unit = {}\n",
    "df_num_stock_per_unit = {}\n",
    "for idx, row in df_ratio.iterrows():\n",
    "    adr = idx.split(\"_\")[0]\n",
    "    stock = idx.split(\"_\")[1]\n",
    "    df_num_adr_per_unit[adr] = max(1, row[\"adr_num_per_stock\"])\n",
    "    df_num_stock_per_unit[stock] = max(1, row[\"stock_num_per_adr\"])\n",
    "\n",
    "aus_adr_underlying_pairs = [\n",
    "    [\"ATHE\", \"ATH\"],[\"GENE\", \"GTG\"],[\"IMMP\", \"IMM\"],[\"IMRN\",\"IMC\"],[\"KZIA\", \"KZA\"],\n",
    "    [\"MESO\",\"MSB\"],[\"PLL\", \"PLL\"],[\"WBK\",\"WBC\"]\n",
    "]\n",
    "\n",
    "hk_adr_underlying_pairs = [\n",
    "    [\"ACH\", \"2600\"],[\"BGNE\", \"6160\"],[\"CEA\",\"670\"],[\"HNP\", \"902\"],[\"LFC\", \"2628\"],[\"PTR\", \"857\"],\n",
    "    [\"SHI\", \"338\"],[\"SNP\",\"386\"],[\"ZNH\", \"1055\"]\n",
    "]\n",
    "\n",
    "jpn_adr_underlying_pairs = [\n",
    "    [\"CAJ\", \"7751\"],[\"HMC\",\"7267\"],[\"IX\",\"8591\"],[\"MFG\",\"8411\"],[\"MUFG\",\"8306\"],[\"NMR\",\"8604\"],\n",
    "    [\"SMFG\",\"8316\"],[\"SONY\",\"6758\"],[\"TAK\", \"4502\"],[\"TM\", \"7203\"]\n",
    "]\n",
    "\n",
    "country_info = {\n",
    "    \"Australia\":{\"Currency\": \"AUD\", \n",
    "                \"Exchange\": \"SMART\",\n",
    "                \"Pairs\": aus_adr_underlying_pairs},\n",
    "    \n",
    "    \"Japan\":{\"Currency\": \"JPY\", \n",
    "             \"Exchange\": \"TSEJ\",\n",
    "             \"Pairs\": jpn_adr_underlying_pairs},\n",
    "    \n",
    "    \"HK\":{\"Currency\": \"HKD\", \n",
    "         \"Exchange\": \"SEHK\",\n",
    "         \"Pairs\": hk_adr_underlying_pairs},\n",
    "    \n",
    "}\n",
    "\n",
    "forex_pairs = [(\"AUD\", \"USD\"),  (\"USD\", \"HKD\"), (\"USD\",\"JPY\")]\n",
    "\n",
    "\n",
    "# functions return the market opening time adjusted for DST\n",
    "\n",
    "us_dst = {\n",
    "        2021: (datetime(2021, 3, 14), datetime(2021, 11, 7)),\n",
    "        2020: (datetime(2020, 3, 8),  datetime(2020, 11, 1)),\n",
    "        2019: (datetime(2019, 3, 10), datetime(2019, 11, 3)),\n",
    "        2018: (datetime(2018, 3, 11), datetime(2018, 11, 4)),\n",
    "        2017: (datetime(2017, 3, 12), datetime(2017, 11, 5)),\n",
    "        2016: (datetime(2016, 3, 13), datetime(2016, 11, 6)),\n",
    "        2015: (datetime(2015, 3, 9),  datetime(2015, 11, 2)),\n",
    "    } \n",
    "\n",
    "def next_weekday(date_now):\n",
    "    if date_now.weekday()<4:\n",
    "        return date_now + timedelta(days = 1)\n",
    "    \n",
    "    while date_now.weekday()>3:\n",
    "        date_now += timedelta(days = 1)\n",
    "        \n",
    "    return date_now\n",
    "\n",
    "def next_market_open_day(date_now):\n",
    "    '''\n",
    "    Returns today if Mon - Thurs, returns next Mon if Fri thru Sun\n",
    "    '''\n",
    "    while date_now.weekday()>4:\n",
    "        date_now += timedelta(days = 1)\n",
    "    return date_now\n",
    "\n",
    "def AUS_opening(date_now):\n",
    "    date_adj = next_market_open_day(date_now)\n",
    "    us_start, us_end = us_dst[date_adj.year]\n",
    "    if us_start < date_adj and date_adj < us_end:\n",
    "        return datetime.combine(date_adj,time(10,0)) - timedelta(hours = 14)\n",
    "    else:\n",
    "        return datetime.combine(date_adj, time(10,0)) - timedelta(hours = 15)\n",
    "\n",
    "def AUS_closing(date_now):\n",
    "    open_time = AUS_opening(date_now)\n",
    "    return open_time + timedelta(hours = 6)\n",
    "\n",
    "def HK_opening(date_now):\n",
    "    date_adj = next_market_open_day(date_now)\n",
    "    start, end = us_dst[date_adj.year]\n",
    "    if start < date_adj and date_adj < end:\n",
    "        return datetime.combine(date_adj,time(9,30)) - timedelta(hours = 12)\n",
    "    else:\n",
    "        return datetime.combine(date_adj, time(9,30)) - timedelta(hours = 13)\n",
    "    \n",
    "def HK_closing(date_now):\n",
    "    open_time = HK_opening(date_now)\n",
    "    return open_time + timedelta(hours = 6.5)\n",
    "    \n",
    "def JPN_opening(date_now):\n",
    "    date_now = next_market_open_day(date_now)\n",
    "    start, end = us_dst[date_now.year]\n",
    "    if start < date_now and date_now < end:\n",
    "        return datetime.combine(date_now,time(9,0)) - timedelta(hours = 13)\n",
    "    else:\n",
    "        return datetime.combine(date_now,time(9,0)) - timedelta(hours = 14)\n",
    "    \n",
    "def JPN_closing(date_now):\n",
    "    open_time = JPN_opening(date_now)\n",
    "    return open_time + timedelta(hours = 6)\n",
    "\n",
    "def US_opening(date_now):\n",
    "    return datetime.combine(next_market_open_day(date_now),time(9,30))\n",
    "\n",
    "def US_closing(date_now):\n",
    "    return datetime.combine(next_market_open_day(date_now),time(16,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize data lists, hyperparameters etc\n",
    "\n",
    "path_data = \"live_trading_data/\"\n",
    "df_forex = pd.DataFrame({\"date\":[]})\n",
    "def initialize_forex():\n",
    "    global df_forex, country_info\n",
    "\n",
    "    now = datetime.now()\n",
    "    df_forex = pd.read_csv(f\"{path_data}df_forex.csv\")\n",
    "    df_forex[\"date\"] = [datetime.strptime(date_time, '%Y-%m-%d %H:%M:%S') for date_time in df_forex[\"date\"]]\n",
    "    pull_head = datetime.combine(max(now-timedelta(days = round(8/5*100)),df_forex[\"date\"].iloc[-1]).date(),time(17,0))\n",
    "\n",
    "\n",
    "    now = datetime.combine(datetime.now().date(), time(17,5))\n",
    "    df_temp_jpy = pd.DataFrame({\"date\":[]})\n",
    "    df_temp_hkd = pd.DataFrame({\"date\":[]})\n",
    "    df_temp_aud = pd.DataFrame({\"date\":[]})\n",
    "    df_temp_holder = {\n",
    "        \"AUD.USD\" : df_temp_aud,\n",
    "        \"JPY.USD\" : df_temp_jpy,\n",
    "        \"HKD.USD\" : df_temp_hkd\n",
    "    }\n",
    "    while pull_head < now:\n",
    "        print(pull_head.date())\n",
    "        for currency1, currency2 in forex_pairs:\n",
    "\n",
    "            history = \"2 D\"\n",
    "            freq = \"1 min\"\n",
    "            side = \"BID_ASK\"\n",
    "\n",
    "            forex_contract = Contract(symbol = currency1, secType = \"CASH\", exchange = \"IDEALPRO\", currency = currency2)\n",
    "            ib.qualifyContracts(forex_contract)\n",
    "            try:\n",
    "                df_temp = get_data(forex_contract, history, freq, side, pull_head)    \n",
    "\n",
    "                if currency2 == \"USD\":\n",
    "                    df_temp[f\"{currency1}.{currency2}\"] = (df_temp[\"open\"] + df_temp[\"close\"])/2\n",
    "                    forex_string = f\"{currency1}.{currency2}\"\n",
    "                else:\n",
    "                    df_temp[f\"{currency2}.{currency1}\"] = 2/(df_temp[\"open\"] + df_temp[\"close\"])\n",
    "                    forex_string = f\"{currency2}.{currency1}\"\n",
    "\n",
    "                df_temp[\"date\"] = df_temp[\"date\"].astype('datetime64[s]')\n",
    "    #             if pull_head == datetime(2021,4,21): print(df_temp)\n",
    "\n",
    "                df_temp_holder[forex_string] = pd.merge(df_temp_holder[forex_string], df_temp[[\"date\",forex_string]], how = \"outer\")\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "\n",
    "        pull_head += timedelta(days = 1)\n",
    "    df_temp_2 = pd.merge(df_temp_holder[\"HKD.USD\"],pd.merge(df_temp_holder[\"AUD.USD\"], df_temp_holder[\"JPY.USD\"],  how = \"outer\"), on = \"date\", how = \"outer\")\n",
    "    df_forex = pd.merge(df_forex,df_temp_2, how = \"outer\").drop_duplicates(keep = \"first\")\n",
    "    #     df_forex.to_csv(f\"{path_data}df_forex.csv\", index = False)\n",
    "    print(\"df_forex initialized\")\n",
    "\n",
    "def save_forex():\n",
    "    global df_forex\n",
    "    df_forex.drop_duplicates(\"date\")\n",
    "    df_forex.to_csv(f\"{path_data}df_forex.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_info = {\n",
    "    \"Australia\":{\"Currency\": \"AUD\", \n",
    "                \"Exchange\": \"SMART\",\n",
    "                \"Pairs\": aus_adr_underlying_pairs},\n",
    "    \n",
    "    \"Japan\":{\"Currency\": \"JPY\", \n",
    "             \"Exchange\": \"TSEJ\",\n",
    "             \"Pairs\": jpn_adr_underlying_pairs},\n",
    "    \n",
    "    \"HK\":{\"Currency\": \"HKD\", \n",
    "         \"Exchange\": \"SEHK\",\n",
    "         \"Pairs\": hk_adr_underlying_pairs},\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "# Store all the historical adr/underlying open and close data\n",
    "\n",
    "#define a function to get IB data. endDate is the last date of the historical data \n",
    "\n",
    "def get_data(contract, history, freq, side, endDate =''):\n",
    "    bar = ib.reqHistoricalData(\n",
    "        contract,\n",
    "        endDateTime = endDate,\n",
    "        durationStr=history,\n",
    "        barSizeSetting= freq,\n",
    "        whatToShow=side,\n",
    "        useRTH=True,\n",
    "        formatDate=1)\n",
    "    return util.df(bar)\n",
    "\n",
    "def pull_asian_close(days = 1):\n",
    "    global df_global, country_info\n",
    "\n",
    "    today = datetime.now().date()\n",
    "    history = f\"{days} D\"\n",
    "    freq = \"1 Day\"\n",
    "    side = 'Trades'\n",
    "\n",
    "    df_asian_close = pd.DataFrame({\"date\":[]})\n",
    "    for key in country_info.keys():\n",
    "        pairs = country_info[key][\"Pairs\"]\n",
    "        exchange = country_info[key][\"Exchange\"]\n",
    "        currency = country_info[key][\"Currency\"]\n",
    "        \n",
    "        for p in pairs:\n",
    "            underlying = p[1]\n",
    "            contract = Contract(symbol = underlying, secType = 'STK', exchange = exchange, currency = currency)\n",
    "\n",
    "            df = get_data(contract, history, freq, side, endDate =today)\n",
    "            ratio = max(1, df_ratio.loc[f\"{p[0]}_{p[1]}\"][\"stock_num_per_adr\"])\n",
    "            df[f\"underlying_{underlying}_close_per_unit\"] = df[\"close\"] * ratio\n",
    "\n",
    "            df = df.loc[:, [\"date\", \"close\", f\"underlying_{underlying}_close_per_unit\", \"volume\"]]\n",
    "            col_name = \"underlying_\" + underlying + \"_close\"\n",
    "            df = df.rename(columns = {\"close\":col_name, \"volume\": f\"underlying_{underlying}_volume\"})\n",
    "            \n",
    "            df_asian_close = pd.merge(df_asian_close, df, how = \"outer\")\n",
    "\n",
    "            \n",
    "    df_global = pd.merge(df_global, df_asian_close,how = \"outer\").sort_values(\"date\")\n",
    "\n",
    "    \n",
    "    \n",
    "def pull_us_close(days = 1):\n",
    "    global df_global, country_info\n",
    "\n",
    "    today = datetime.now().date()\n",
    "    history = f\"{days} D\"\n",
    "    freq = \"1 Day\"\n",
    "    side = 'Trades'\n",
    "    \n",
    "    df_us_close = pd.DataFrame({\"date\":[]})\n",
    "    for key in country_info.keys():\n",
    "        pairs = country_info[key][\"Pairs\"]\n",
    "        exchange = \"SMART\"\n",
    "        currency = \"USD\"\n",
    "        \n",
    "        for p in pairs:\n",
    "            underlying = p[0] # get the ticker of the ADR\n",
    "            contract = Contract(symbol = underlying, secType = 'STK', exchange = exchange, currency = currency)\n",
    "            df = get_data(contract, history, freq, side, endDate ='')\n",
    "            ratio = max(1, df_ratio.loc[f\"{p[0]}_{p[1]}\"][\"adr_num_per_stock\"])\n",
    "            df[f\"adr_{p[0]}_close_per_unit\"] = df[\"close\"] * ratio\n",
    "            df = df.loc[:, [\"date\", \"close\", f\"adr_{p[0]}_close_per_unit\", \"volume\" ]]\n",
    "            col_name = \"adr_\" + underlying + \"_close\"\n",
    "            df[\"volume\"] *= 100\n",
    "            df = df.rename(columns = {\"close\":col_name, \"volume\": f\"adr_{underlying}_volume\"})\n",
    "            df_us_close = pd.merge(df_us_close, df, how = 'outer')\n",
    "            \n",
    "    df_global = pd.merge(df_global, df_us_close,how = 'outer').sort_values(\"date\")\n",
    "    \n",
    "def update_df_global_with_forex():\n",
    "    global df_global, df_forex\n",
    "    \n",
    "    us_opens = [datetime.combine(x, time(9,30)) - timedelta(minutes = 30) for x in df_global[\"date\"]]\n",
    "    forex_before_us_opens = df_forex[df_forex[\"date\"].isin(us_opens)].drop_duplicates([\"date\"]).sort_values([\"date\"]).reset_index(drop = True)\n",
    "    forex_before_us_opens[\"date\"] = [datetime.date(x) for x in forex_before_us_opens[\"date\"]]\n",
    "    forex_before_us_opens.columns = [\"date\", \"JPY.USD_before_us_open\", \"AUD.USD_before_us_open\", \"HKD.USD_before_us_open\"]\n",
    "\n",
    "    # Add extra date\n",
    "    dates = list(df_global[\"date\"])\n",
    "    last_date = dates[-1]\n",
    "    dates.append(next_weekday(last_date))\n",
    "    aus_opens = [AUS_opening(datetime.combine(x, time(0,0))) - timedelta(minutes = 30) for x in dates]\n",
    "    hk_opens = [HK_opening(datetime.combine(x, time(0,0))) - timedelta(minutes = 30) for x in dates]\n",
    "    jap_opens = [JPN_opening(datetime.combine(x, time(0,0))) - timedelta(minutes = 30) for x in dates]\n",
    "    aus_forex_opens =  df_forex[df_forex[\"date\"].isin(aus_opens)].drop_duplicates([\"date\"]).sort_values([\"date\"]).reset_index(drop = True)\n",
    "    hk_forex_opens =  df_forex[df_forex[\"date\"].isin(hk_opens)].drop_duplicates([\"date\"]).sort_values([\"date\"]).reset_index(drop = True)\n",
    "    jap_forex_opens =  df_forex[df_forex[\"date\"].isin(jap_opens)].drop_duplicates([\"date\"]).sort_values([\"date\"]).reset_index(drop = True)\n",
    "    aus_forex_opens[\"date\"] += timedelta(days = 1)\n",
    "    hk_forex_opens[\"date\"] += timedelta(days = 1)\n",
    "    jap_forex_opens[\"date\"] += timedelta(days = 1)\n",
    "    aus_forex_opens[\"date\"] = [datetime.date(x) for x in aus_forex_opens[\"date\"]]\n",
    "    hk_forex_opens[\"date\"] = [datetime.date(x) for x in hk_forex_opens[\"date\"]]\n",
    "    jap_forex_opens[\"date\"] = [datetime.date(x) for x in jap_forex_opens[\"date\"]]\n",
    "    forex_before_asian_opens = pd.merge(pd.merge(aus_forex_opens[[\"date\", \"AUD.USD\"]], jap_forex_opens[[\"date\", \"JPY.USD\"]], how = \"outer\"),\n",
    "                                        hk_forex_opens[[\"date\", \"HKD.USD\"]], how = \"outer\")\n",
    "    forex_before_asian_opens.columns = [\"date\", \"AUD.USD_before_asian_open\", \"JPY.USD_before_asian_open\", \"HKD.USD_before_asian_open\"]\n",
    "\n",
    "    df_global = pd.merge(df_global, \n",
    "                         pd.merge(forex_before_us_opens, forex_before_asian_opens, how = \"outer\"),\n",
    "                         how = \"outer\").sort_values(\"date\")\n",
    "    df_global = df_global[df_global[\"date\"] != date(2020, 12, 25)]\n",
    "    df_global.reset_index(inplace = True, drop = True)\n",
    "\n",
    "def pull_forex_data(history = \"2 D\", freq = \"1 min\", side = \"BID_ASK\", end_date = \"\" ):\n",
    "    '''\n",
    "    Updates all three forex pairs\n",
    "    '''\n",
    "    \n",
    "    global df_global, country_info, forex_pairs, test, df_forex\n",
    "\n",
    "    df_temp = pd.DataFrame({\"date\":[]})\n",
    "    for currency1, currency2 in forex_pairs:\n",
    "        contract = Contract(symbol = currency1, secType = 'CASH', exchange = \"IDEALPRO\", currency = currency2)\n",
    "        df = get_data(contract, history, freq, side)\n",
    "\n",
    "        if currency2 == \"USD\":\n",
    "            df[f\"{currency1}.{currency2}\"] = (df[\"open\"] + df[\"close\"])/2\n",
    "            forex_string = f\"{currency1}.{currency2}\"\n",
    "        else:\n",
    "            df[f\"{currency2}.{currency1}\"] = 2/(df[\"open\"] + df[\"close\"])\n",
    "            forex_string = f\"{currency2}.{currency1}\"\n",
    "        df_temp = pd.merge(df_temp, df[['date',forex_string]], how = \"outer\")\n",
    "    \n",
    "    df_forex = pd.merge(df_forex, df_temp, how = \"outer\")\n",
    "    df_forex.drop_duplicates(inplace = True)\n",
    "    update_df_global_with_forex()\n",
    "    \n",
    "def convert_price_asian_close():\n",
    "    \n",
    "    \"\"\"\n",
    "    Convert the last Asian prices we pulled before US open into US dollars\n",
    "    Using the most recent forex data\n",
    "    \"\"\"\n",
    "    global df_global, df_forex, df_ratio, country_info\n",
    "    \n",
    "    # We use the last \n",
    "    for key in country_info:\n",
    "        pairs = country_info[key][\"Pairs\"]\n",
    "        for pair in pairs:\n",
    "            underlying_col_name = f\"underlying_{pair[1]}_close\"\n",
    "            pair_name =  pair[0] + \"_\" + pair[1]\n",
    "            ratio = df_ratio.loc[pair_name,\"adr_num_per_stock\"] # Determing number of adr per stock\n",
    "            \n",
    "            forex_col_name = country_info[key][\"Currency\"]+\".USD\"\n",
    "            fx = df_forex.loc[len(df_forex)-1, forex_col_name]\n",
    "            price_in_usd = df_global.loc[len(df_global)-1, underlying_col_name]*ratio*fx\n",
    "            \n",
    "            df_global.at[len(df_global)-1, underlying_col_name] = price_in_usd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def place_order(country, security, sectype, side, quantity, price):\n",
    "    global order_books\n",
    "    exchange = country_info[country][\"Exchange\"]\n",
    "    currenct = country_info[country][\"Currency\"]\n",
    "    \n",
    "    # Define order \n",
    "    contract = Contract(symbol = security, secType = 'STK', exchange =exchange, currency = currency)\n",
    "    order = LimitOrder(side,quantity,price)\n",
    "    \n",
    "    # Place the order\n",
    "    msg = ib.placeOrder(contract, order)\n",
    "    orderId = msg.order.orderId\n",
    "    \n",
    "    # Add the orderId to orderbook\n",
    "    name =  security +\"_\"+ sectype\n",
    "    order_books[name].add(orderId)\n",
    "\n",
    "def check_open_order(security, sectype = \"underlying\"):\n",
    "    \"\"\"\n",
    "    Check if we have open order for this particular security\n",
    "    Args: \n",
    "    security (str) name of security\n",
    "    sectype(str): takes th evalue either \"adr\" or \"underlying\"\n",
    "    \n",
    "    return: the quantity of open orders (orders that we wanted to trade but not traded) of a particular security\n",
    "    \n",
    "    \"\"\"\n",
    "    global order_books\n",
    "    ct = 0\n",
    "    lookup = security +\"_\"+ sectype\n",
    "    all_orders = order_books[lookup]\n",
    "    open_orders = ib.openOrders()\n",
    "    for o in openOders:\n",
    "        if o.orderId in all_orders:\n",
    "            ct += o.totalQuantity\n",
    "        \n",
    "    return ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairs we have chosen to trade\n",
    "trading_limits = {\"Australia\" : 2, \"China\" : 2, \"Japan\" : 2}\n",
    "allocation = {\"Australia\" : 0.25, \"China\" : 0.4, \"Japan\" : 0.35}\n",
    "country_to_forex = {\"Australia\" : \"AUD.USD\", \"China\" : \"HKD.USD\", \"Japan\" : \"JPY.USD\"}\n",
    "\n",
    "list_pairs = [(\"Japan\", \"SMFG_8316\"), \n",
    "              (\"Japan\", \"IX_8591\"),\n",
    "              (\"Japan\", \"TM_7203\"),\n",
    "              (\"Japan\", \"MFG_8411\"),\n",
    "              (\"China\", \"BGNE_6160\"), \n",
    "              (\"China\", \"SNP_386\"), \n",
    "              (\"China\", \"HNP_902\"), \n",
    "              (\"China\", \"CEA_670\"),\n",
    "              (\"China\", \"ACH_2600\"),\n",
    "              (\"Australia\", \"MESO_MSB\"),\n",
    "              (\"Australia\", \"IMMP_IMM\"),\n",
    "              (\"Australia\", \"PLL_PLL\"),\n",
    "              (\"Australia\", \"KZIA_KZA\"),\n",
    "              (\"Australia\", \"IMRN_IMC\")]\n",
    "\n",
    "full_list_pairs = [('Australia', 'ATHE_ATH'),\n",
    "                   ('Australia', 'GENE_GTG'),\n",
    "                   ('Australia', 'IMMP_IMM'),\n",
    "                   ('Australia', 'IMRN_IMC'),\n",
    "                   ('Australia', 'JHX_JHX'),\n",
    "                   ('Australia', 'KZIA_KZA'),\n",
    "                   ('Australia', 'MESO_MSB'),\n",
    "                   ('Australia', 'PLL_PLL'),\n",
    "                   ('Australia', 'WBK_WBC'),\n",
    "                   ('China', 'ACH_2600'),\n",
    "                   ('China', 'BGNE_6160'),\n",
    "                   ('China', 'CEA_670'),\n",
    "                   ('China', 'HNP_902'),\n",
    "                   ('China', 'LFC_2628'),\n",
    "                   ('China', 'PTR_857'),\n",
    "                   ('China', 'SHI_338'),\n",
    "                   ('China', 'SNP_386'),\n",
    "                   ('China', 'ZNH_1055'),\n",
    "                   ('Japan', 'CAJ_7751'),\n",
    "                   ('Japan', 'HMC_7267'),\n",
    "                   ('Japan', 'IX_8591'),\n",
    "                   ('Japan', 'MFG_8411'),\n",
    "                   ('Japan', 'MUFG_8306'),\n",
    "                   ('Japan', 'NMR_8604'),\n",
    "                   ('Japan', 'SMFG_8316'),\n",
    "                   ('Japan', 'SONY_6758'),\n",
    "                   ('Japan', 'TAK_4502'),\n",
    "                   ('Japan', 'TM_7203')]\n",
    "\n",
    "fname = 'logs/results_all.txt'\n",
    "with open(fname, 'r') as f:\n",
    "    is_res = f.readlines()\n",
    "hp = {}\n",
    "for i in range(len(full_list_pairs)):\n",
    "    hp[full_list_pairs[i]] = [float(x) for x in is_res[i*5 + 4].split(\"(\")[1].split(\")\")[0].split(\", \")]\n",
    "    \n",
    "hp_dict = {}\n",
    "for (country, adr) in list_pairs:\n",
    "    hp_dict[(country, adr)] = {}\n",
    "    hp_dict[(country, adr)][\"lookback\"] = int(hp[(country, adr)][0])\n",
    "    hp_dict[(country, adr)][\"entry\"] = hp[(country, adr)][1]\n",
    "    hp_dict[(country, adr)][\"exit\"] = hp[(country, adr)][2]\n",
    "    hp_dict[(country, adr)][\"stop_loss\"] = hp[(country, adr)][3]\n",
    "    # Fraction of cash allocated to each adr-stock pair\n",
    "    hp_dict[(country, adr)][\"allocation\"] = allocation[country]/trading_limits[country]\n",
    "    hp_dict[(country, adr)][\"original_allocation\"] = allocation[country]/trading_limits[country]\n",
    "    \n",
    "actual_hps = pd.read_csv(\"actual_hps.csv\", index_col = 0)\n",
    "for idx, row in actual_hps.iterrows():\n",
    "    country = row[\"country\"]\n",
    "    adr = row[\"adr\"]\n",
    "    hp_dict[(country, adr)][\"limit_exit\"] = max(row[\"actual_exit\"], hp_dict[(country, adr)][\"exit\"])\n",
    "    hp_dict[(country, adr)][\"limit_entry\"] = min(row[\"actual_entry\"], hp_dict[(country, adr)][\"entry\"])\n",
    "    if hp_dict[(country, adr)][\"limit_entry\"] < hp_dict[(country, adr)][\"limit_exit\"]:\n",
    "        hp_dict[(country, adr)][\"limit_entry\"] = hp_dict[(country, adr)][\"entry\"]\n",
    "    \n",
    "\n",
    "diff_record_dict = {}\n",
    "for (country, adr) in list_pairs:\n",
    "    diff_record_dict[(country, adr)] = deque(maxlen = 2*hp_dict[(country, adr)][\"lookback\"])\n",
    "    \n",
    "conditions = {}\n",
    "for (country, adr) in list_pairs:\n",
    "    conditions[(country, adr)] = {}\n",
    "    conditions[(country, adr)][\"enter_cond1\"] = False\n",
    "    conditions[(country, adr)][\"exit_cond1\"] = False\n",
    "    conditions[(country, adr)][\"enter_cond2\"] = False\n",
    "    conditions[(country, adr)][\"exit_cond2\"] = False\n",
    "\n",
    "positions = {}\n",
    "for (country, adr) in list_pairs:\n",
    "    positions[(country, adr)] = {}\n",
    "    positions[(country, adr)][\"stock_pos\"] = 0\n",
    "    positions[(country, adr)][\"adr_pos\"] = 0\n",
    "    positions[(country, adr)][\"prev_adr_pos\"] = 0\n",
    "    positions[(country, adr)][\"holding_period\"] = None\n",
    "    positions[(country, adr)][\"trade_type\"] = None\n",
    "    \n",
    "actions_to_take = {}\n",
    "for (country, adr) in list_pairs:\n",
    "    actions_to_take[(country, adr)] = {}\n",
    "    \n",
    "cash = 249000\n",
    "var_limit = 0.1\n",
    "max_drawdown_limit = 0.2\n",
    "sigma_limit = 0.05\n",
    "stop_loss_limit = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bef_aus_jap_open():\n",
    "    return datetime.now().time() >= time(19, 0) and datetime.now().time() <= time(20, 45)\n",
    "    #return True\n",
    "#     return False\n",
    "\n",
    "def bef_hk_open():\n",
    "    return datetime.now().time() > time(20, 45) and datetime.now().time() <= time(22, 30)\n",
    "    # return True\n",
    "#     return False\n",
    "    \n",
    "def bef_us_open():\n",
    "#     return True\n",
    "    return datetime.now().time() >= time(8, 30) and datetime.now().time() <= time(10, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_diff_queue():\n",
    "    global list_pairs, diff_record_dict, df_global\n",
    "    for country, adr in list_pairs:\n",
    "        ticker_ADR, ticker_underlying = adr.split(\"_\")\n",
    "        diff_record = deque(maxlen = 2*hp_dict[(country, adr)][\"lookback\"])\n",
    "        for idx, row in df_global.iterrows():\n",
    "            if bef_us_open():\n",
    "                if idx > 0:\n",
    "                    prev_row = df_global.loc[idx - 1]\n",
    "                    # Append Asian Open data\n",
    "                    adr_price = prev_row[f\"adr_{ticker_ADR}_close_per_unit\"]\n",
    "                    stock_price = prev_row[f\"underlying_{ticker_underlying}_close_per_unit\"]\n",
    "                    adjusted_stock_price = stock_price*row[f\"{country_to_forex[country]}_before_asian_open\"]\n",
    "                    diff = adr_price - adjusted_stock_price\n",
    "                    if not np.isnan(diff):\n",
    "                        diff_record.append(diff)\n",
    "\n",
    "                    # Append US Open data\n",
    "                    adr_price = prev_row[f\"adr_{ticker_ADR}_close_per_unit\"]\n",
    "                    stock_price = row[f\"underlying_{ticker_underlying}_close_per_unit\"]\n",
    "                    adjusted_stock_price = stock_price*row[f\"{country_to_forex[country]}_before_us_open\"]\n",
    "                    diff = adr_price - adjusted_stock_price\n",
    "                    if not np.isnan(diff):\n",
    "                        diff_record.append(diff)\n",
    "\n",
    "            elif bef_aus_jap_open() or bef_hk_open():\n",
    "                if idx > 0 and idx < len(df_global) - 1:\n",
    "                    prev_row = df_global.loc[idx - 1]\n",
    "                    next_row = df_global.loc[idx + 1]\n",
    "\n",
    "                    # Append US Open data\n",
    "                    adr_price = prev_row[f\"adr_{ticker_ADR}_close_per_unit\"]\n",
    "                    stock_price = row[f\"underlying_{ticker_underlying}_close_per_unit\"]\n",
    "                    adjusted_stock_price = stock_price*row[f\"{country_to_forex[country]}_before_us_open\"]\n",
    "                    diff = adr_price - adjusted_stock_price\n",
    "                    if not np.isnan(diff):\n",
    "                        diff_record.append(diff)\n",
    "\n",
    "                    # Append Asian Open data\n",
    "                    adr_price = row[f\"adr_{ticker_ADR}_close_per_unit\"]\n",
    "                    stock_price = row[f\"underlying_{ticker_underlying}_close_per_unit\"]\n",
    "                    adjusted_stock_price = stock_price*next_row[f\"{country_to_forex[country]}_before_asian_open\"]\n",
    "                    diff = adr_price - adjusted_stock_price\n",
    "                    if not np.isnan(diff):\n",
    "                        diff_record.append(diff)\n",
    "\n",
    "        diff_record_dict[(country,adr)] = diff_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_z_score(diff_record):\n",
    "    mean = np.array(diff_record).mean()\n",
    "    std = np.array(diff_record).std()\n",
    "    return mean, std, (diff_record[-1] - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_actions_to_take():\n",
    "    global list_pairs, diff_record_dict, df_global, actions_to_take\n",
    "    \n",
    "    if bef_aus_jap_open():\n",
    "        pairs_to_evaluate = [x for x in list_pairs if x[0] in [\"Australia\", \"Japan\"]]\n",
    "    elif bef_hk_open():\n",
    "        pairs_to_evaluate = [x for x in list_pairs if x[0] == \"China\"]\n",
    "    elif bef_us_open():\n",
    "        pairs_to_evaluate = list_pairs\n",
    "    else:\n",
    "        pairs_to_evaluate = []\n",
    "        \n",
    "    for (country, adr) in pairs_to_evaluate:\n",
    "        ticker_ADR, ticker_underlying = tuple(adr.split(\"_\"))\n",
    "        \n",
    "#         if len(actions_to_take[(country, adr)]) == 1:\n",
    "#             for key in actions_to_take[(country, adr)]:\n",
    "#                 # Update volume\n",
    "#                 actions_to_take[(country, adr)][key][\"volume\"] = \"MATCH POSITION\"\n",
    "                \n",
    "#         elif len(actions_to_take[(country, adr)]) == 0:\n",
    "        # Calculate\n",
    "        mean, std, z_score = calculate_z_score(diff_record_dict[(country,adr)])\n",
    "        entry = hp_dict[(country, adr)][\"entry\"]\n",
    "        exit = hp_dict[(country, adr)][\"exit\"]\n",
    "        print(z_score, entry)\n",
    "        ### MISSING NO POSITION COMMENT\n",
    "        if z_score > entry:\n",
    "            # Enter\n",
    "            # Market orders\n",
    "            if bef_aus_jap_open() or bef_hk_open():\n",
    "                # Calculate volume and price\n",
    "                # Before Asian open\n",
    "                stock_adt = df_global.loc[len(df_global)-6:len(df_global)-2][f\"underlying_{ticker_underlying}_volume\"].dropna().median()\n",
    "                adr_adt = df_global.loc[len(df_global)-6:len(df_global)-2][f\"adr_{ticker_ADR}_volume\"].dropna().median()\n",
    "                adr_volume = (0.1*adr_adt)/df_num_adr_per_unit[ticker_ADR]\n",
    "                stock_volume = (0.1*stock_adt)/df_num_stock_per_unit[ticker_underlying]\n",
    "                adr_price_per_unit = df_global.loc[len(df_global)-2, f\"adr_{ticker_ADR}_close_per_unit\"]\n",
    "                stock_price_per_unit = df_global.loc[len(df_global)-2, f\"underlying_{ticker_underlying}_close_per_unit\"]*df_global.loc[len(df_global)-1, f\"{country_to_forex[country]}_before_asian_open\"]\n",
    "                print(df_global.loc[len(df_global)-1, f\"{country_to_forex[country]}_before_asian_open\"])\n",
    "                units = int(min((hp_dict[(country, adr)][\"allocation\"]*cash)/adr_price_per_unit,\n",
    "                                (hp_dict[(country, adr)][\"allocation\"]*cash)/stock_price_per_unit, \n",
    "                                adr_volume, \n",
    "                                stock_volume))\n",
    "                adr_quantity = int(units*df_num_adr_per_unit[ticker_ADR])\n",
    "                stock_quantity = int(units*df_num_stock_per_unit[ticker_underlying])\n",
    "                stock_values = np.array(df_global.loc[len(df_global)-101:len(df_global)-2, f\"underlying_{ticker_underlying}_close\"]*stock_quantity)\n",
    "                adjusted_stock_values = stock_values*np.array(df_global.loc[len(df_global)-100:len(df_global)-1, f\"{country_to_forex[country]}_before_asian_open\"])\n",
    "                adr_values = np.array(df_global.loc[len(df_global)-101:len(df_global)-2, f\"adr_{ticker_ADR}_close\"]*adr_quantity)\n",
    "                mask = np.isnan(adjusted_stock_values) | np.isnan(adr_values)\n",
    "                adjusted_stock_values = adjusted_stock_values[~mask]\n",
    "                adr_values = adr_values[~mask]\n",
    "                sigma, var, max_drawdown_abs = get_risk_statistics(adjusted_stock_values, adr_values, var_ci = 0.95)\n",
    "                adjusted_cash = cash*allocation[country]\n",
    "                if (var > adjusted_cash*var_limit or \n",
    "                    max_drawdown_abs > max_drawdown_limit*adjusted_cash or \n",
    "                    sigma > adjusted_cash*sigma_limit):\n",
    "                    frac = min((adjusted_cash*var_limit)/var, \n",
    "                               (adjusted_cash*max_drawdown_limit)/max_drawdown_abs,\n",
    "                              (adjusted_cash*sigma_limit)/sigma)\n",
    "                    units = int(frac*units)\n",
    "                    if units == 0:\n",
    "                        continue\n",
    "                    adr_quantity = int(units*df_num_adr_per_unit[ticker_ADR])\n",
    "                    stock_quantity = int(units*df_num_stock_per_unit[ticker_underlying])\n",
    "\n",
    "                execution_stock_price_per_unit = adr_price_per_unit - (mean + hp_dict[(country, adr)][\"limit_entry\"]*std)\n",
    "                execution_stock_price = execution_stock_price_per_unit/df_num_stock_per_unit[ticker_underlying]\n",
    "                execution_stock_price_in_local_currency = execution_stock_price/df_global.loc[len(df_global)-1, f\"{country_to_forex[country]}_before_asian_open\"]\n",
    "                liquidation_stock_price_per_unit = adr_price_per_unit - (mean + hp_dict[(country, adr)][\"limit_exit\"]*std)\n",
    "                liquidation_stock_price = liquidation_stock_price_per_unit/df_num_stock_per_unit[ticker_underlying]\n",
    "                liquidation_stock_price_in_local_currency = liquidation_stock_price/df_global.loc[len(df_global)-1, f\"{country_to_forex[country]}_before_asian_open\"]\n",
    "\n",
    "                actions_to_take[(country, adr)][\"stock\"] = {}\n",
    "                actions_to_take[(country, adr)][\"stock\"][\"action\"] = \"buy\"\n",
    "                actions_to_take[(country, adr)][\"adr\"] = {}\n",
    "                actions_to_take[(country, adr)][\"adr\"][\"action\"] = \"sell\"\n",
    "                actions_to_take[(country, adr)][\"stock\"][\"volume\"] = stock_quantity\n",
    "                actions_to_take[(country, adr)][\"stock\"][\"execution_price\"] = execution_stock_price_in_local_currency\n",
    "                actions_to_take[(country, adr)][\"stock\"][\"liquidation_price\"] = liquidation_stock_price_in_local_currency\n",
    "                actions_to_take[(country, adr)][\"adr\"][\"volume\"] = -1\n",
    "                actions_to_take[(country, adr)][\"adr\"][\"execution_price\"] = -1\n",
    "            else: \n",
    "                # Calculate volume and price\n",
    "                # Before US open\n",
    "                stock_adt = df_global.loc[len(df_global)-5:len(df_global)-1][f\"underlying_{ticker_underlying}_volume\"].dropna().median()\n",
    "                adr_adt = df_global.loc[len(df_global)-6:len(df_global)-2][f\"adr_{ticker_ADR}_volume\"].dropna().median()\n",
    "                adr_volume = (0.1*adr_adt)/df_num_adr_per_unit[ticker_ADR]\n",
    "                stock_volume = (0.1*stock_adt)/df_num_stock_per_unit[ticker_underlying]\n",
    "                adr_price_per_unit = df_global.loc[len(df_global)-2, f\"adr_{ticker_ADR}_close_per_unit\"]\n",
    "                stock_price_per_unit = df_global.loc[len(df_global)-1, f\"underlying_{ticker_underlying}_close_per_unit\"]*df_global.loc[len(df_global)-1, f\"{country_to_forex[country]}_before_us_open\"]\n",
    "                units = int(min((hp_dict[(country, adr)][\"allocation\"]*cash)/adr_price_per_unit,\n",
    "                                (hp_dict[(country, adr)][\"allocation\"]*cash)/stock_price_per_unit, \n",
    "                                adr_volume, \n",
    "                                stock_volume))\n",
    "                adr_quantity = int(units*df_num_adr_per_unit[ticker_ADR])\n",
    "                stock_quantity = int(units*df_num_stock_per_unit[ticker_underlying])\n",
    "                stock_values = np.array(df_global.loc[len(df_global)-100:len(df_global)-1, f\"underlying_{ticker_underlying}_close\"]*stock_quantity)\n",
    "                adjusted_stock_values = stock_values*np.array(df_global.loc[len(df_global)-100:len(df_global)-1, f\"{country_to_forex[country]}_before_us_open\"])\n",
    "                adr_values = np.array(df_global.loc[len(df_global)-101:len(df_global)-2, f\"adr_{ticker_ADR}_close\"]*adr_quantity)\n",
    "                mask = np.isnan(adjusted_stock_values) | np.isnan(adr_values)\n",
    "                adjusted_stock_values = adjusted_stock_values[~mask]\n",
    "                adr_values = adr_values[~mask]\n",
    "                sigma, var, max_drawdown_abs = get_risk_statistics(adjusted_stock_values, adr_values, var_ci = 0.95)\n",
    "                adjusted_cash = cash*allocation[country]\n",
    "                if (var > adjusted_cash*var_limit or \n",
    "                    max_drawdown_abs > max_drawdown_limit*adjusted_cash or \n",
    "                    sigma > adjusted_cash*sigma_limit):\n",
    "                    frac = min((adjusted_cash*var_limit)/var, \n",
    "                               (adjusted_cash*max_drawdown_limit)/max_drawdown_abs,\n",
    "                              (adjusted_cash*sigma_limit)/sigma)\n",
    "                    print(frac)\n",
    "                    units = int(frac*units)\n",
    "                    if units == 0:\n",
    "                        continue\n",
    "                    adr_quantity = int(units*df_num_adr_per_unit[ticker_ADR])\n",
    "                    stock_quantity = int(units*df_num_stock_per_unit[ticker_underlying])\n",
    "\n",
    "                execution_adr_price_per_unit = stock_price_per_unit + mean + hp_dict[(country, adr)][\"limit_entry\"]*std\n",
    "                execution_adr_price = execution_adr_price_per_unit/df_num_adr_per_unit[ticker_ADR]\n",
    "                liquidation_adr_price_per_unit = stock_price_per_unit + mean + hp_dict[(country, adr)][\"limit_exit\"]*std\n",
    "                liquidation_adr_price = liquidation_adr_price_per_unit/df_num_adr_per_unit[ticker_ADR]\n",
    "\n",
    "                actions_to_take[(country, adr)][\"stock\"] = {}\n",
    "                actions_to_take[(country, adr)][\"stock\"][\"action\"] = \"buy\"\n",
    "                actions_to_take[(country, adr)][\"adr\"] = {}\n",
    "                actions_to_take[(country, adr)][\"adr\"][\"action\"] = \"sell\"\n",
    "                actions_to_take[(country, adr)][\"adr\"][\"volume\"] = adr_quantity\n",
    "                actions_to_take[(country, adr)][\"adr\"][\"execution_price\"] = execution_adr_price\n",
    "                actions_to_take[(country, adr)][\"adr\"][\"liquidation_price\"] = liquidation_adr_price\n",
    "                actions_to_take[(country, adr)][\"stock\"][\"volume\"] = -1\n",
    "                actions_to_take[(country, adr)][\"stock\"][\"execution_price\"] = -1                \n",
    "            ### MISSING POSITION CHECK\n",
    "        elif z_score < exit:\n",
    "            actions_to_take[(country, adr)][\"stock\"] = {}\n",
    "            actions_to_take[(country, adr)][\"stock\"][\"action\"] = \"sell\"\n",
    "            # Update volume\n",
    "            actions_to_take[(country, adr)][\"stock\"][\"volume\"] = \"LIQUIDATE\"\n",
    "            actions_to_take[(country, adr)][\"stock\"][\"execution_price\"] = -1\n",
    "            actions_to_take[(country, adr)][\"adr\"] = {}\n",
    "            actions_to_take[(country, adr)][\"adr\"][\"action\"] = \"buy\"\n",
    "            # Update volume\n",
    "            actions_to_take[(country, adr)][\"adr\"][\"volume\"] = \"LIQUIDATE\"\n",
    "            actions_to_take[(country, adr)][\"adr\"][\"execution_price\"] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-22\n",
      "2021-04-23\n",
      "2021-04-24\n",
      "2021-04-25\n",
      "df_forex initialized\n"
     ]
    }
   ],
   "source": [
    "initialize_forex()\n",
    "# Always run these 3 lines together\n",
    "pull_asian_close(120)\n",
    "pull_us_close(120)\n",
    "pull_forex_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.1985600416361768 1.5\n",
      "-1.7516168513193402 1.5\n",
      "0.2138122849846296 2.0\n",
      "-0.91473625715529 1.5\n",
      "-0.05351387926196785 1.0\n",
      "0.707255628481671 1.0\n",
      "1.1079112209633917 1.0\n",
      "0.24251110864322006 1.0\n",
      "-0.6313880499526702 1.0\n",
      "2.4408100492789067 1.0\n",
      "-0.23236648235914845 1.0\n",
      "-0.0023737728651908705 1.0\n",
      "-0.14997539543781935 1.0\n",
      "-0.8753950456157195 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{('Japan',\n",
       "  'SMFG_8316'): {'stock': {'action': 'sell',\n",
       "   'volume': 'LIQUIDATE',\n",
       "   'execution_price': -1}, 'adr': {'action': 'buy',\n",
       "   'volume': 'LIQUIDATE',\n",
       "   'execution_price': -1}},\n",
       " ('Japan',\n",
       "  'IX_8591'): {'stock': {'action': 'sell',\n",
       "   'volume': 'LIQUIDATE',\n",
       "   'execution_price': -1}, 'adr': {'action': 'buy',\n",
       "   'volume': 'LIQUIDATE',\n",
       "   'execution_price': -1}},\n",
       " ('Japan',\n",
       "  'TM_7203'): {'stock': {'action': 'sell',\n",
       "   'volume': 'LIQUIDATE',\n",
       "   'execution_price': -1}, 'adr': {'action': 'buy',\n",
       "   'volume': 'LIQUIDATE',\n",
       "   'execution_price': -1}},\n",
       " ('Japan',\n",
       "  'MFG_8411'): {'stock': {'action': 'sell',\n",
       "   'volume': 'LIQUIDATE',\n",
       "   'execution_price': -1}, 'adr': {'action': 'buy',\n",
       "   'volume': 'LIQUIDATE',\n",
       "   'execution_price': -1}},\n",
       " ('China', 'BGNE_6160'): {},\n",
       " ('China', 'SNP_386'): {},\n",
       " ('China',\n",
       "  'HNP_902'): {'stock': {'action': 'buy',\n",
       "   'volume': -1,\n",
       "   'execution_price': -1}, 'adr': {'action': 'sell',\n",
       "   'volume': 1360,\n",
       "   'execution_price': 14.146386106714365,\n",
       "   'liquidation_price': 14.043152891634}},\n",
       " ('China', 'CEA_670'): {},\n",
       " ('China',\n",
       "  'ACH_2600'): {'stock': {'action': 'sell',\n",
       "   'volume': 'LIQUIDATE',\n",
       "   'execution_price': -1}, 'adr': {'action': 'buy',\n",
       "   'volume': 'LIQUIDATE',\n",
       "   'execution_price': -1}},\n",
       " ('Australia',\n",
       "  'MESO_MSB'): {'stock': {'action': 'buy',\n",
       "   'volume': -1,\n",
       "   'execution_price': -1}, 'adr': {'action': 'sell',\n",
       "   'volume': 3657,\n",
       "   'execution_price': 8.260995626750237,\n",
       "   'liquidation_price': 8.030558198952605}},\n",
       " ('Australia',\n",
       "  'IMMP_IMM'): {'stock': {'action': 'sell',\n",
       "   'volume': 'LIQUIDATE',\n",
       "   'execution_price': -1}, 'adr': {'action': 'buy',\n",
       "   'volume': 'LIQUIDATE',\n",
       "   'execution_price': -1}},\n",
       " ('Australia',\n",
       "  'PLL_PLL'): {'stock': {'action': 'sell',\n",
       "   'volume': 'LIQUIDATE',\n",
       "   'execution_price': -1}, 'adr': {'action': 'buy',\n",
       "   'volume': 'LIQUIDATE',\n",
       "   'execution_price': -1}},\n",
       " ('Australia', 'KZIA_KZA'): {},\n",
       " ('Australia',\n",
       "  'IMRN_IMC'): {'stock': {'action': 'sell',\n",
       "   'volume': 'LIQUIDATE',\n",
       "   'execution_price': -1}, 'adr': {'action': 'buy',\n",
       "   'volume': 'LIQUIDATE',\n",
       "   'execution_price': -1}}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####### CALCULATES ORDERS TO MAKE######### \n",
    "# actions_to_take = {}\n",
    "for (country, adr) in list_pairs:\n",
    "    actions_to_take[(country, adr)] = {}\n",
    "diff_record_dict = {}\n",
    "for (country, adr) in list_pairs:\n",
    "    diff_record_dict[(country, adr)] = deque(maxlen = 2*hp_dict[(country, adr)][\"lookback\"])\n",
    "populate_diff_queue()\n",
    "populate_actions_to_take()\n",
    "actions_to_take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_actions(active_country):\n",
    "    global list_pairs, diff_record_dict, df_global, actions_to_take\n",
    "    for (country, adr) in list_pairs:\n",
    "        if country != active_country:\n",
    "            continue\n",
    "        if len(actions_to_take[(country, adr)]) == 1:\n",
    "            volume = portfolio[(country, adr)]*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_ratio' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ff70cd7a3c32>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_ratio\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_ratio' is not defined"
     ]
    }
   ],
   "source": [
    "df_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Japan', 'SMFG_8316'),\n",
       " ('Japan', 'IX_8591'),\n",
       " ('Japan', 'TM_7203'),\n",
       " ('Japan', 'MFG_8411'),\n",
       " ('China', 'BGNE_6160'),\n",
       " ('China', 'SNP_386'),\n",
       " ('China', 'HNP_902'),\n",
       " ('China', 'CEA_670'),\n",
       " ('China', 'ACH_2600'),\n",
       " ('Australia', 'MESO_MSB'),\n",
       " ('Australia', 'IMMP_IMM'),\n",
       " ('Australia', 'PLL_PLL'),\n",
       " ('Australia', 'KZIA_KZA'),\n",
       " ('Australia', 'IMRN_IMC')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pair</th>\n",
       "      <th>adr_num_per_stock</th>\n",
       "      <th>stock_num_per_adr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IMMP_IMM</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IMRN_IMC</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KZIA_KZA</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MESO_MSB</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PLL_PLL</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>IX_8591</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MFG_8411</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SMFG_8316</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>TM_7203</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ACH_2600</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>BGNE_6160</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>CEA_670</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>HNP_902</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>SNP_386</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Pair  adr_num_per_stock  stock_num_per_adr\n",
       "2    IMMP_IMM           0.100000               10.0\n",
       "3    IMRN_IMC           0.025000               40.0\n",
       "5    KZIA_KZA           0.100000               10.0\n",
       "6    MESO_MSB           0.200000                5.0\n",
       "7     PLL_PLL           0.010000              100.0\n",
       "11    IX_8591           0.200000                5.0\n",
       "12   MFG_8411           5.000000                0.2\n",
       "15  SMFG_8316           5.000000                0.2\n",
       "18    TM_7203           0.500000                2.0\n",
       "19   ACH_2600           0.040000               25.0\n",
       "20  BGNE_6160           0.076923               13.0\n",
       "21    CEA_670           0.020000               50.0\n",
       "22    HNP_902           0.025000               40.0\n",
       "26    SNP_386           0.010000              100.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"adr_stock_ratio.csv\", index_col = 0)\n",
    "df[df[\"Pair\"].isin([x[1] for x in list_pairs])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### USE THIS TO CLEAN ACTIONS TO TAKE AFTER MAKING ORDER ####\n",
    "key_list = list(actions_to_take.keys())\n",
    "executed_list = []\n",
    "for key in key_list:\n",
    "    if key in executed_list:\n",
    "#         actions_to_take[key].pop('adr')\n",
    "        pass\n",
    "    else:\n",
    "        actions_to_take.pop(key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('Australia',\n",
       "  'MESO_MSB'): {'stock': {'action': 'buy',\n",
       "   'volume': -1,\n",
       "   'execution_price': -1}}}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error 1100, reqId -1: Connectivity between IB and Trader Workstation has been lost.\n",
      "Error 1102, reqId -1: Connectivity between IB and Trader Workstation has been restored - data maintained. All data farms are connected: usfarm; hkhmds; cashhmds; ushmds; secdefil.\n",
      "Error 1100, reqId -1: Connectivity between IB and Trader Workstation has been lost.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def place_order(country, security, sectype, side, quantity, price, market_order = False):\n",
    "    global order_books\n",
    "    exchange = country_info[country][\"Ex change\"]\n",
    "    currenct = country_info[country][\"Currency\"]\n",
    "    \n",
    "    # Define order \n",
    "    contract = Contract(symbol = security, secType = 'STK', exchange =exchange, currency = currency)\n",
    "    if market_order == True:\n",
    "        order =  MarketOrder(side,quantity)\n",
    "    else:\n",
    "        order = LimitOrder(side,quantity,price)\n",
    "    \n",
    "    # Place the order\n",
    "    msg = ib.placeOrder(contract, order)\n",
    "    orderId = msg.order.orderId\n",
    "    \n",
    "    # Add the orderId to orderbook\n",
    "    name =  security +\"_\"+ sectype\n",
    "    order_books[name].add(orderId)\n",
    "    order_records[orderId] = my_order(security, side, sectype, quantity)\n",
    "    \n",
    "\n",
    "def print_order_records():\n",
    "    global order_records\n",
    "    \n",
    "    #sys.__stdout__.write(\"orderId\\tSecurity\\tSecType\\tOrderType\\tStatus\\tTotal\\tFilled\\tAvgPrice\\n\")\n",
    "    print(datetime.now())\n",
    "    print(\"orderId\\tSecurity\\tSecType\\tOrderType\\tStatus\\tTotal\\tFilled\\tAvgPrice\\n\")\n",
    "    for order in order_records:\n",
    "        orderId = order\n",
    "        Security = order_records[order].sec_name\n",
    "        Type = order_records[order].sec_type\n",
    "        Status = order_records[order].status\n",
    "        Total = order_records[order].total_quantity\n",
    "        Filled = order_records[order].filled_quantity\n",
    "        AvgPrice = order_records[order].avg_filled_price\n",
    "        order_type = order_records[order].order_type\n",
    "        sys.__stdout__.write(f\"{orderId}\\t{Security}\\t\\t{Type}\\t{order_type}\\t\\t{Status}\\t{Total}\\t{Filled}\\t{AvgPrice}\\n\")\n",
    "\n",
    "\n",
    "def print_portfolio():\n",
    "    global portfolio\n",
    "    #sys.__stdout__.write(\"Security\\tPosition\\n\")\n",
    "    print(datetime.now())\n",
    "    print(\"Security\\tPosition\\n\")\n",
    "    for key in portfolio:\n",
    "        \n",
    "        if len(key) <= 7:\n",
    "            #sys.__stdout__.write(f\"{key}\\t\\t{portfolio[key]}\\n\")\n",
    "            print(f\"{key}\\t\\t{portfolio[key]}\\n\")\n",
    "        else:\n",
    "            print(f\"{key}\\t{portfolio[key]}\\n\")\n",
    "            #sys.__stdout__.write(f\"{key}\\t{portfolio[key]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio = {\"USD\":0, \"HKD\": 0, \"AUD\": 0, \"JPY\": 0}\n",
    "for key in country_info:\n",
    "    for p in country_info[key][\"Pairs\"]:\n",
    "        adr = p[0]+\"_adr\"\n",
    "        portfolio[adr] = 0\n",
    "        \n",
    "        under = p[1] + \"_stk\"\n",
    "        portfolio[under] = 0\n",
    "        \n",
    "        \n",
    "\n",
    "class my_order:\n",
    "    def __init__(self, sec_name, order_type, sec_type, total_quantity):\n",
    "        \n",
    "        self.sec_name = sec_name\n",
    "        self.sec_type = sec_type # if foreign currency, put \"\"\n",
    "        self.order_type = order_type # Either \"buy\" or \"sell\"\n",
    "        self.status = \"Pending\"\n",
    "        self.total_quantity = total_quantity\n",
    "\n",
    "        self.filled_quantity = 0\n",
    "        self.avg_filled_price = 0.0\n",
    "\n",
    "def reset_portfolio():\n",
    "    global portfolio\n",
    "        \n",
    "    for key in country_info:\n",
    "        for p in country_info[key][\"Pairs\"]:\n",
    "            adr = p[0]+\"_adr\"\n",
    "            portfolio[adr] = 0\n",
    "\n",
    "            under = p[1] + \"_stk\"\n",
    "            portfolio[under] = 0\n",
    "\n",
    "        \n",
    "\n",
    "def onOrderStatus(trade): \n",
    "    global order_records, portfolio\n",
    "    print(f\"Update in order {trade.order.orderId}\")\n",
    "#     print(trade.orderStatus.status == 'Cancelled')\n",
    "    #print('order status' + trade.orderStatus.status)\n",
    "    orderId = trade.order.orderId\n",
    "    if trade.orderStatus.status == 'Cancelled':\n",
    "        order_records[orderId].status = \"Cancelled\"\n",
    "        print(\"Order has been cancelled.\")\n",
    "    elif trade.orderStatus.status == \"Filled\":\n",
    "        \n",
    "        change = trade.orderStatus.filled - order_records[orderId].filled_quantity\n",
    "        order_records[orderId].filled_quantity = trade.orderStatus.filled\n",
    "        order_records[orderId].avg_filled_price = trade.orderStatus.avgFillPrice\n",
    "        \n",
    "        sec_type = order_records[orderId].sec_type\n",
    "        sec =  order_records[orderId].sec_name\n",
    "        order_type = order_records[orderId].order_type\n",
    "        if sec_type == 'adr':\n",
    "            if order_records[orderId].order_type == \"buy\":\n",
    "                portfolio[sec + sec_type] += change\n",
    "            else:\n",
    "                portfolio[sec + sec_type] -= change\n",
    "                \n",
    "        elif sec_type == \"underlying\":\n",
    "            if order_records[orderId].order_type == \"buy\":\n",
    "                portfolio[sec + '_stk'] += change\n",
    "            else:\n",
    "                portfolio[sec +  '_stk'] -= change\n",
    "        \n",
    "        \n",
    "        print(f\"{trade.orderStatus.filled} shares of {order_type} {sec} ({sec_type}) has been filled at an average price of {trade.orderStatus.avgFillPrice}\")\n",
    "        if rade.orderStatus.remaining == 0:\n",
    "            order_records[orderId].status = \"Completed\"\n",
    "            print(\"Order is completed!\")\n",
    "            \n",
    "    else:\n",
    "        print(trade.orderStatus.status)\n",
    "    \n",
    "\n",
    "def liquidate():\n",
    "    \"\"\"\n",
    "    Func to liquidate all our current positions\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    global portfolio\n",
    "    positions = ib.positions()  # A list of positions, according to IB\n",
    "    for position in positions:\n",
    "        action = \"\"\n",
    "        contract = position.contract\n",
    "        if position.position > 0: # Number of active Long positions\n",
    "            action = 'Sell' # to offset the long positions\n",
    "        elif position.position < 0: # Number of active Short positions\n",
    "            action = 'Buy' # to offset the short positions\n",
    "        else:\n",
    "            assert False\n",
    "        totalQuantity = abs(position.position)\n",
    "        order = MarketOrder(action=action, totalQuantity=totalQuantity)\n",
    "        trade = ib.placeOrder(contract, order)\n",
    "        orderId = trade.orderId\n",
    "        security = trade.contract.symbol\n",
    "        sectype = \"\"\n",
    "        if trade.contract.currency == \"USD\": # if usd, we know it is an adr\n",
    "            sectype = \"adr\"\n",
    "        else:\n",
    "            sectype = \"stk\"\n",
    "            \n",
    "\n",
    "            # Add the orderId to orderbook\n",
    "        name =  security +\"_\"+ sectype\n",
    "        order_books[name].add(orderId)\n",
    "        order_records[orderId] = my_order(security, action, sectype, position)\n",
    "\n",
    "\n",
    "        print(f'Flatten Position: {action} {totalQuantity} {contract.localSymbol}')\n",
    "    reset_portfolio()\n",
    "    \n",
    "\n",
    "def onExecDetails(trade,fill): \n",
    "    print('order exec details' + fill.execution)\n",
    "    ib.execDetailsEvent+=onExecDetails \n",
    "    ib.orderStatusEvent+=onOrderStatus\n",
    "\n",
    "    # fut = Future('ES', '20181221', 'GLOBEX') \n",
    "    # ib.qualifyContracts(fut) \n",
    "\n",
    "    contract = Stock('TSLA', 'SMART', 'USD')\n",
    "    ib.qualifyContracts(contract)\n",
    "\n",
    "\n",
    "    order =LimitOrder('BUY', 1,1) \n",
    "    trade = ib.placeOrder(contract, order) \n",
    "    print(trade)\n",
    "    order_records[trade.order.orderId] = my_order(\"AAPL\",\"Stock\",\"buy\",1)\n",
    "\n",
    "    ib.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.30 am\n",
    "    # Pull Historical Forex Data (Minute, for lookback window)\n",
    "    # Pull Close Data for Asian Market at 9am (Before US Market opens)\n",
    "# 9.28 am \n",
    "    # Pull Forex Data for three currencies (For Z score)\n",
    "    # Calculate Z Score \n",
    "    # for each pair:\n",
    "        # if invested:\n",
    "            # if risk condition or exit condition:\n",
    "                # liquidate\n",
    "            # else:\n",
    "                # continue\n",
    "        # if entry condition:\n",
    "            # determine order size from risk metric and ADT over last 5 days\n",
    "            # if 0: no order made\n",
    "            # else: \n",
    "                # Define contract\n",
    "                # make order (What order? Market Order?)\n",
    "\n",
    "\n",
    "# 6 pm\n",
    "    # Pull Close Data for US Market at 6pm (Before Asian Market opens)\n",
    "    # Pull Historical Forex Data\n",
    "\n",
    "# 2 min before Asian Market Open\n",
    "    # Pull Forex Data\n",
    "    # Calculate Z score using market close and minute forex data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "security = \"MESO\"\n",
    "sectype = \"adr\"\n",
    "side = 'sell'\n",
    "quantity = 132\n",
    "price = 8.26\n",
    "\n",
    "contract = Contract(symbol = security, secType = 'STK', exchange = \"SMART\", currency = \"USD\")\n",
    "\n",
    "order = LimitOrder(side,quantity,price)\n",
    "\n",
    "# Place the order\n",
    "msg = ib.placeOrder(contract, order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.merge(df_forex,df_temp, how = \"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>JPY.USD</th>\n",
       "      <th>AUD.USD</th>\n",
       "      <th>HKD.USD</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>average</th>\n",
       "      <th>barCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-11-30 17:15:00</td>\n",
       "      <td>0.009587</td>\n",
       "      <td>0.734580</td>\n",
       "      <td>0.129011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-11-30 17:16:00</td>\n",
       "      <td>0.009587</td>\n",
       "      <td>0.734490</td>\n",
       "      <td>0.129011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-11-30 17:17:00</td>\n",
       "      <td>0.009587</td>\n",
       "      <td>0.734445</td>\n",
       "      <td>0.129011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-11-30 17:18:00</td>\n",
       "      <td>0.009587</td>\n",
       "      <td>0.734460</td>\n",
       "      <td>0.129011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-11-30 17:19:00</td>\n",
       "      <td>0.009586</td>\n",
       "      <td>0.734565</td>\n",
       "      <td>0.129011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-11-30 17:20:00</td>\n",
       "      <td>0.009586</td>\n",
       "      <td>0.734610</td>\n",
       "      <td>0.129011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-11-30 17:21:00</td>\n",
       "      <td>0.009586</td>\n",
       "      <td>0.734630</td>\n",
       "      <td>0.129011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-11-30 17:22:00</td>\n",
       "      <td>0.009586</td>\n",
       "      <td>0.734635</td>\n",
       "      <td>0.129011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-11-30 17:23:00</td>\n",
       "      <td>0.009587</td>\n",
       "      <td>0.734695</td>\n",
       "      <td>0.129011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-11-30 17:24:00</td>\n",
       "      <td>0.009587</td>\n",
       "      <td>0.734695</td>\n",
       "      <td>0.129011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2020-11-30 17:25:00</td>\n",
       "      <td>0.009587</td>\n",
       "      <td>0.734765</td>\n",
       "      <td>0.129011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2020-11-30 17:26:00</td>\n",
       "      <td>0.009586</td>\n",
       "      <td>0.734875</td>\n",
       "      <td>0.129011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2020-11-30 17:27:00</td>\n",
       "      <td>0.009586</td>\n",
       "      <td>0.734875</td>\n",
       "      <td>0.129011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2020-11-30 17:28:00</td>\n",
       "      <td>0.009586</td>\n",
       "      <td>0.734860</td>\n",
       "      <td>0.129011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2020-11-30 17:29:00</td>\n",
       "      <td>0.009586</td>\n",
       "      <td>0.734840</td>\n",
       "      <td>0.129011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2020-11-30 17:30:00</td>\n",
       "      <td>0.009586</td>\n",
       "      <td>0.734850</td>\n",
       "      <td>0.129011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2020-11-30 17:31:00</td>\n",
       "      <td>0.009587</td>\n",
       "      <td>0.734855</td>\n",
       "      <td>0.129011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2020-11-30 17:32:00</td>\n",
       "      <td>0.009587</td>\n",
       "      <td>0.734880</td>\n",
       "      <td>0.129011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2020-11-30 17:33:00</td>\n",
       "      <td>0.009586</td>\n",
       "      <td>0.734850</td>\n",
       "      <td>0.129012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2020-11-30 17:34:00</td>\n",
       "      <td>0.009587</td>\n",
       "      <td>0.734770</td>\n",
       "      <td>0.129012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2020-11-30 17:35:00</td>\n",
       "      <td>0.009587</td>\n",
       "      <td>0.734770</td>\n",
       "      <td>0.129001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2020-11-30 17:36:00</td>\n",
       "      <td>0.009587</td>\n",
       "      <td>0.734760</td>\n",
       "      <td>0.129000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2020-11-30 17:37:00</td>\n",
       "      <td>0.009587</td>\n",
       "      <td>0.734740</td>\n",
       "      <td>0.129000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2020-11-30 17:38:00</td>\n",
       "      <td>0.009587</td>\n",
       "      <td>0.734750</td>\n",
       "      <td>0.129000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2020-11-30 17:39:00</td>\n",
       "      <td>0.009587</td>\n",
       "      <td>0.734740</td>\n",
       "      <td>0.129000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2020-11-30 17:40:00</td>\n",
       "      <td>0.009587</td>\n",
       "      <td>0.734685</td>\n",
       "      <td>0.129000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2020-11-30 17:41:00</td>\n",
       "      <td>0.009587</td>\n",
       "      <td>0.734740</td>\n",
       "      <td>0.129000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2020-11-30 17:42:00</td>\n",
       "      <td>0.009587</td>\n",
       "      <td>0.735005</td>\n",
       "      <td>0.129000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2020-11-30 17:43:00</td>\n",
       "      <td>0.009587</td>\n",
       "      <td>0.734960</td>\n",
       "      <td>0.129000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2020-11-30 17:44:00</td>\n",
       "      <td>0.009587</td>\n",
       "      <td>0.734940</td>\n",
       "      <td>0.129000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151125</th>\n",
       "      <td>2021-04-21 13:41:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775540</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.77553</td>\n",
       "      <td>0.77557</td>\n",
       "      <td>0.77551</td>\n",
       "      <td>0.77555</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151126</th>\n",
       "      <td>2021-04-21 13:42:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775515</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.77551</td>\n",
       "      <td>0.77557</td>\n",
       "      <td>0.77546</td>\n",
       "      <td>0.77552</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151127</th>\n",
       "      <td>2021-04-21 13:43:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775455</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.77545</td>\n",
       "      <td>0.77548</td>\n",
       "      <td>0.77543</td>\n",
       "      <td>0.77546</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151128</th>\n",
       "      <td>2021-04-21 13:44:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775465</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.77546</td>\n",
       "      <td>0.77548</td>\n",
       "      <td>0.77545</td>\n",
       "      <td>0.77547</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151129</th>\n",
       "      <td>2021-04-21 13:45:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775475</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.77547</td>\n",
       "      <td>0.77552</td>\n",
       "      <td>0.77542</td>\n",
       "      <td>0.77548</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151130</th>\n",
       "      <td>2021-04-21 13:46:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775465</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.77546</td>\n",
       "      <td>0.77552</td>\n",
       "      <td>0.77544</td>\n",
       "      <td>0.77547</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151131</th>\n",
       "      <td>2021-04-21 13:47:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.77549</td>\n",
       "      <td>0.77555</td>\n",
       "      <td>0.77544</td>\n",
       "      <td>0.77551</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151132</th>\n",
       "      <td>2021-04-21 13:48:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775585</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.77558</td>\n",
       "      <td>0.77563</td>\n",
       "      <td>0.77550</td>\n",
       "      <td>0.77559</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151133</th>\n",
       "      <td>2021-04-21 13:49:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775635</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.77563</td>\n",
       "      <td>0.77568</td>\n",
       "      <td>0.77560</td>\n",
       "      <td>0.77564</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151134</th>\n",
       "      <td>2021-04-21 13:50:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775570</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.77556</td>\n",
       "      <td>0.77563</td>\n",
       "      <td>0.77554</td>\n",
       "      <td>0.77558</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151135</th>\n",
       "      <td>2021-04-21 13:51:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775590</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.77558</td>\n",
       "      <td>0.77562</td>\n",
       "      <td>0.77555</td>\n",
       "      <td>0.77560</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151136</th>\n",
       "      <td>2021-04-21 13:52:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775555</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.77555</td>\n",
       "      <td>0.77559</td>\n",
       "      <td>0.77551</td>\n",
       "      <td>0.77556</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151137</th>\n",
       "      <td>2021-04-21 13:53:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775535</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.77553</td>\n",
       "      <td>0.77559</td>\n",
       "      <td>0.77550</td>\n",
       "      <td>0.77554</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151138</th>\n",
       "      <td>2021-04-21 13:54:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775515</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.77551</td>\n",
       "      <td>0.77556</td>\n",
       "      <td>0.77549</td>\n",
       "      <td>0.77552</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151139</th>\n",
       "      <td>2021-04-21 13:55:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775555</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.77555</td>\n",
       "      <td>0.77559</td>\n",
       "      <td>0.77554</td>\n",
       "      <td>0.77556</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151140</th>\n",
       "      <td>2021-04-21 13:56:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775585</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.77558</td>\n",
       "      <td>0.77562</td>\n",
       "      <td>0.77554</td>\n",
       "      <td>0.77559</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151141</th>\n",
       "      <td>2021-04-21 13:57:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775660</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.77565</td>\n",
       "      <td>0.77572</td>\n",
       "      <td>0.77561</td>\n",
       "      <td>0.77567</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151142</th>\n",
       "      <td>2021-04-21 13:58:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775660</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.77565</td>\n",
       "      <td>0.77570</td>\n",
       "      <td>0.77555</td>\n",
       "      <td>0.77567</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151143</th>\n",
       "      <td>2021-04-21 13:59:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775555</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.77554</td>\n",
       "      <td>0.77559</td>\n",
       "      <td>0.77551</td>\n",
       "      <td>0.77557</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151144</th>\n",
       "      <td>2021-04-21 14:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775655</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.77564</td>\n",
       "      <td>0.77569</td>\n",
       "      <td>0.77554</td>\n",
       "      <td>0.77567</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151145</th>\n",
       "      <td>2021-04-21 14:01:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.77561</td>\n",
       "      <td>0.77567</td>\n",
       "      <td>0.77557</td>\n",
       "      <td>0.77564</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151146</th>\n",
       "      <td>2021-04-21 14:02:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775595</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.77558</td>\n",
       "      <td>0.77564</td>\n",
       "      <td>0.77555</td>\n",
       "      <td>0.77561</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151147</th>\n",
       "      <td>2021-04-21 14:03:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775570</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.77556</td>\n",
       "      <td>0.77561</td>\n",
       "      <td>0.77555</td>\n",
       "      <td>0.77558</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151148</th>\n",
       "      <td>2021-04-21 14:04:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775560</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.77555</td>\n",
       "      <td>0.77557</td>\n",
       "      <td>0.77555</td>\n",
       "      <td>0.77557</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151149</th>\n",
       "      <td>2021-04-21 14:05:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775580</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.77557</td>\n",
       "      <td>0.77564</td>\n",
       "      <td>0.77555</td>\n",
       "      <td>0.77559</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151150</th>\n",
       "      <td>2021-04-21 14:06:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775655</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.77565</td>\n",
       "      <td>0.77568</td>\n",
       "      <td>0.77561</td>\n",
       "      <td>0.77566</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151151</th>\n",
       "      <td>2021-04-21 14:07:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.77562</td>\n",
       "      <td>0.77567</td>\n",
       "      <td>0.77560</td>\n",
       "      <td>0.77564</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151152</th>\n",
       "      <td>2021-04-21 14:08:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775610</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.77560</td>\n",
       "      <td>0.77563</td>\n",
       "      <td>0.77559</td>\n",
       "      <td>0.77562</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151153</th>\n",
       "      <td>2021-04-21 14:09:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775585</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.77557</td>\n",
       "      <td>0.77562</td>\n",
       "      <td>0.77555</td>\n",
       "      <td>0.77560</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151154</th>\n",
       "      <td>2021-04-21 14:10:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775560</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.77555</td>\n",
       "      <td>0.77558</td>\n",
       "      <td>0.77553</td>\n",
       "      <td>0.77557</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151155 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      date   JPY.USD   AUD.USD   HKD.USD     open     high  \\\n",
       "0      2020-11-30 17:15:00  0.009587  0.734580  0.129011      NaN      NaN   \n",
       "1      2020-11-30 17:16:00  0.009587  0.734490  0.129011      NaN      NaN   \n",
       "2      2020-11-30 17:17:00  0.009587  0.734445  0.129011      NaN      NaN   \n",
       "3      2020-11-30 17:18:00  0.009587  0.734460  0.129011      NaN      NaN   \n",
       "4      2020-11-30 17:19:00  0.009586  0.734565  0.129011      NaN      NaN   \n",
       "5      2020-11-30 17:20:00  0.009586  0.734610  0.129011      NaN      NaN   \n",
       "6      2020-11-30 17:21:00  0.009586  0.734630  0.129011      NaN      NaN   \n",
       "7      2020-11-30 17:22:00  0.009586  0.734635  0.129011      NaN      NaN   \n",
       "8      2020-11-30 17:23:00  0.009587  0.734695  0.129011      NaN      NaN   \n",
       "9      2020-11-30 17:24:00  0.009587  0.734695  0.129011      NaN      NaN   \n",
       "10     2020-11-30 17:25:00  0.009587  0.734765  0.129011      NaN      NaN   \n",
       "11     2020-11-30 17:26:00  0.009586  0.734875  0.129011      NaN      NaN   \n",
       "12     2020-11-30 17:27:00  0.009586  0.734875  0.129011      NaN      NaN   \n",
       "13     2020-11-30 17:28:00  0.009586  0.734860  0.129011      NaN      NaN   \n",
       "14     2020-11-30 17:29:00  0.009586  0.734840  0.129011      NaN      NaN   \n",
       "15     2020-11-30 17:30:00  0.009586  0.734850  0.129011      NaN      NaN   \n",
       "16     2020-11-30 17:31:00  0.009587  0.734855  0.129011      NaN      NaN   \n",
       "17     2020-11-30 17:32:00  0.009587  0.734880  0.129011      NaN      NaN   \n",
       "18     2020-11-30 17:33:00  0.009586  0.734850  0.129012      NaN      NaN   \n",
       "19     2020-11-30 17:34:00  0.009587  0.734770  0.129012      NaN      NaN   \n",
       "20     2020-11-30 17:35:00  0.009587  0.734770  0.129001      NaN      NaN   \n",
       "21     2020-11-30 17:36:00  0.009587  0.734760  0.129000      NaN      NaN   \n",
       "22     2020-11-30 17:37:00  0.009587  0.734740  0.129000      NaN      NaN   \n",
       "23     2020-11-30 17:38:00  0.009587  0.734750  0.129000      NaN      NaN   \n",
       "24     2020-11-30 17:39:00  0.009587  0.734740  0.129000      NaN      NaN   \n",
       "25     2020-11-30 17:40:00  0.009587  0.734685  0.129000      NaN      NaN   \n",
       "26     2020-11-30 17:41:00  0.009587  0.734740  0.129000      NaN      NaN   \n",
       "27     2020-11-30 17:42:00  0.009587  0.735005  0.129000      NaN      NaN   \n",
       "28     2020-11-30 17:43:00  0.009587  0.734960  0.129000      NaN      NaN   \n",
       "29     2020-11-30 17:44:00  0.009587  0.734940  0.129000      NaN      NaN   \n",
       "...                    ...       ...       ...       ...      ...      ...   \n",
       "151125 2021-04-21 13:41:00       NaN  0.775540       NaN  0.77553  0.77557   \n",
       "151126 2021-04-21 13:42:00       NaN  0.775515       NaN  0.77551  0.77557   \n",
       "151127 2021-04-21 13:43:00       NaN  0.775455       NaN  0.77545  0.77548   \n",
       "151128 2021-04-21 13:44:00       NaN  0.775465       NaN  0.77546  0.77548   \n",
       "151129 2021-04-21 13:45:00       NaN  0.775475       NaN  0.77547  0.77552   \n",
       "151130 2021-04-21 13:46:00       NaN  0.775465       NaN  0.77546  0.77552   \n",
       "151131 2021-04-21 13:47:00       NaN  0.775500       NaN  0.77549  0.77555   \n",
       "151132 2021-04-21 13:48:00       NaN  0.775585       NaN  0.77558  0.77563   \n",
       "151133 2021-04-21 13:49:00       NaN  0.775635       NaN  0.77563  0.77568   \n",
       "151134 2021-04-21 13:50:00       NaN  0.775570       NaN  0.77556  0.77563   \n",
       "151135 2021-04-21 13:51:00       NaN  0.775590       NaN  0.77558  0.77562   \n",
       "151136 2021-04-21 13:52:00       NaN  0.775555       NaN  0.77555  0.77559   \n",
       "151137 2021-04-21 13:53:00       NaN  0.775535       NaN  0.77553  0.77559   \n",
       "151138 2021-04-21 13:54:00       NaN  0.775515       NaN  0.77551  0.77556   \n",
       "151139 2021-04-21 13:55:00       NaN  0.775555       NaN  0.77555  0.77559   \n",
       "151140 2021-04-21 13:56:00       NaN  0.775585       NaN  0.77558  0.77562   \n",
       "151141 2021-04-21 13:57:00       NaN  0.775660       NaN  0.77565  0.77572   \n",
       "151142 2021-04-21 13:58:00       NaN  0.775660       NaN  0.77565  0.77570   \n",
       "151143 2021-04-21 13:59:00       NaN  0.775555       NaN  0.77554  0.77559   \n",
       "151144 2021-04-21 14:00:00       NaN  0.775655       NaN  0.77564  0.77569   \n",
       "151145 2021-04-21 14:01:00       NaN  0.775625       NaN  0.77561  0.77567   \n",
       "151146 2021-04-21 14:02:00       NaN  0.775595       NaN  0.77558  0.77564   \n",
       "151147 2021-04-21 14:03:00       NaN  0.775570       NaN  0.77556  0.77561   \n",
       "151148 2021-04-21 14:04:00       NaN  0.775560       NaN  0.77555  0.77557   \n",
       "151149 2021-04-21 14:05:00       NaN  0.775580       NaN  0.77557  0.77564   \n",
       "151150 2021-04-21 14:06:00       NaN  0.775655       NaN  0.77565  0.77568   \n",
       "151151 2021-04-21 14:07:00       NaN  0.775630       NaN  0.77562  0.77567   \n",
       "151152 2021-04-21 14:08:00       NaN  0.775610       NaN  0.77560  0.77563   \n",
       "151153 2021-04-21 14:09:00       NaN  0.775585       NaN  0.77557  0.77562   \n",
       "151154 2021-04-21 14:10:00       NaN  0.775560       NaN  0.77555  0.77558   \n",
       "\n",
       "            low    close  volume  average  barCount  \n",
       "0           NaN      NaN     NaN      NaN       NaN  \n",
       "1           NaN      NaN     NaN      NaN       NaN  \n",
       "2           NaN      NaN     NaN      NaN       NaN  \n",
       "3           NaN      NaN     NaN      NaN       NaN  \n",
       "4           NaN      NaN     NaN      NaN       NaN  \n",
       "5           NaN      NaN     NaN      NaN       NaN  \n",
       "6           NaN      NaN     NaN      NaN       NaN  \n",
       "7           NaN      NaN     NaN      NaN       NaN  \n",
       "8           NaN      NaN     NaN      NaN       NaN  \n",
       "9           NaN      NaN     NaN      NaN       NaN  \n",
       "10          NaN      NaN     NaN      NaN       NaN  \n",
       "11          NaN      NaN     NaN      NaN       NaN  \n",
       "12          NaN      NaN     NaN      NaN       NaN  \n",
       "13          NaN      NaN     NaN      NaN       NaN  \n",
       "14          NaN      NaN     NaN      NaN       NaN  \n",
       "15          NaN      NaN     NaN      NaN       NaN  \n",
       "16          NaN      NaN     NaN      NaN       NaN  \n",
       "17          NaN      NaN     NaN      NaN       NaN  \n",
       "18          NaN      NaN     NaN      NaN       NaN  \n",
       "19          NaN      NaN     NaN      NaN       NaN  \n",
       "20          NaN      NaN     NaN      NaN       NaN  \n",
       "21          NaN      NaN     NaN      NaN       NaN  \n",
       "22          NaN      NaN     NaN      NaN       NaN  \n",
       "23          NaN      NaN     NaN      NaN       NaN  \n",
       "24          NaN      NaN     NaN      NaN       NaN  \n",
       "25          NaN      NaN     NaN      NaN       NaN  \n",
       "26          NaN      NaN     NaN      NaN       NaN  \n",
       "27          NaN      NaN     NaN      NaN       NaN  \n",
       "28          NaN      NaN     NaN      NaN       NaN  \n",
       "29          NaN      NaN     NaN      NaN       NaN  \n",
       "...         ...      ...     ...      ...       ...  \n",
       "151125  0.77551  0.77555    -1.0     -1.0      -1.0  \n",
       "151126  0.77546  0.77552    -1.0     -1.0      -1.0  \n",
       "151127  0.77543  0.77546    -1.0     -1.0      -1.0  \n",
       "151128  0.77545  0.77547    -1.0     -1.0      -1.0  \n",
       "151129  0.77542  0.77548    -1.0     -1.0      -1.0  \n",
       "151130  0.77544  0.77547    -1.0     -1.0      -1.0  \n",
       "151131  0.77544  0.77551    -1.0     -1.0      -1.0  \n",
       "151132  0.77550  0.77559    -1.0     -1.0      -1.0  \n",
       "151133  0.77560  0.77564    -1.0     -1.0      -1.0  \n",
       "151134  0.77554  0.77558    -1.0     -1.0      -1.0  \n",
       "151135  0.77555  0.77560    -1.0     -1.0      -1.0  \n",
       "151136  0.77551  0.77556    -1.0     -1.0      -1.0  \n",
       "151137  0.77550  0.77554    -1.0     -1.0      -1.0  \n",
       "151138  0.77549  0.77552    -1.0     -1.0      -1.0  \n",
       "151139  0.77554  0.77556    -1.0     -1.0      -1.0  \n",
       "151140  0.77554  0.77559    -1.0     -1.0      -1.0  \n",
       "151141  0.77561  0.77567    -1.0     -1.0      -1.0  \n",
       "151142  0.77555  0.77567    -1.0     -1.0      -1.0  \n",
       "151143  0.77551  0.77557    -1.0     -1.0      -1.0  \n",
       "151144  0.77554  0.77567    -1.0     -1.0      -1.0  \n",
       "151145  0.77557  0.77564    -1.0     -1.0      -1.0  \n",
       "151146  0.77555  0.77561    -1.0     -1.0      -1.0  \n",
       "151147  0.77555  0.77558    -1.0     -1.0      -1.0  \n",
       "151148  0.77555  0.77557    -1.0     -1.0      -1.0  \n",
       "151149  0.77555  0.77559    -1.0     -1.0      -1.0  \n",
       "151150  0.77561  0.77566    -1.0     -1.0      -1.0  \n",
       "151151  0.77560  0.77564    -1.0     -1.0      -1.0  \n",
       "151152  0.77559  0.77562    -1.0     -1.0      -1.0  \n",
       "151153  0.77555  0.77560    -1.0     -1.0      -1.0  \n",
       "151154  0.77553  0.77557    -1.0     -1.0      -1.0  \n",
       "\n",
       "[151155 rows x 11 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forex = pd.read_csv(f\"{path_data}df_forex.csv\")\n",
    "df_forex[\"date\"] = [datetime.strptime(date_time, '%Y-%m-%d %H:%M:%S') for date_time in df_forex[\"date\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_info = {\n",
    "    \"Australia\":{\"Currency\": \"AUD\", \n",
    "                \"Exchange\": \"SMART\",\n",
    "                \"Pairs\": aus_adr_underlying_pairs},\n",
    "    \n",
    "    \"Japan\":{\"Currency\": \"JPY\", \n",
    "             \"Exchange\": \"TSEJ\",\n",
    "             \"Pairs\": jpn_adr_underlying_pairs},\n",
    "    \n",
    "    \"HK\":{\"Currency\": \"HKD\", \n",
    "         \"Exchange\": \"SEHK\",\n",
    "         \"Pairs\": hk_adr_underlying_pairs},\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "live_data = {}\n",
    "def pull_live_data():\n",
    "    global live_data, country_info, forex_pairs\n",
    "    \n",
    "    dict_forex = {}\n",
    "    for country in forex_pairs:\n",
    "        currency1, currency2, * = country\n",
    "\n",
    "        history = \"60 S\"\n",
    "        freq = \"1 min\"\n",
    "        side = \"BID_ASK\"\n",
    "\n",
    "        forex_contract = Contract(symbol = currency1, secType = \"CASH\", exchange = \"IDEALPRO\", currency = currency2)\n",
    "        ib.qualifyContracts(forex_contract)\n",
    "        df_temp = get_data(forex_contract, history, freq, side)\n",
    "        \n",
    "        latest_tick = df_temp.iloc[-1]\n",
    "        if currency2 == \"USD\":\n",
    "            live_data[f\"{currency1}.{currency2}\"] = (latest_tick[\"open\"] + latest_tick[\"close\"])/2\n",
    "\n",
    "        else:\n",
    "            live_data[f\"{currency2}.{currency2}\"] = 2/(latest_tick[\"open\"] + latest_tick[\"close\"])\n",
    "            \n",
    "    for country in country_info.keys():\n",
    "        currency = country_info[country][\"Currency\"]\n",
    "        exchange = country_info[country][\"Exchange\"]\n",
    "        pairs_list = country_info[country][\"Pairs\"]\n",
    "        \n",
    "        side = \"Trades\"\n",
    "\n",
    "        for ticker_ADR, ticker_underlying in pairs_list:\n",
    "            contract = Contract(symbol = ticker_ADR, secType = \"STK\", exchange = \"SMART\", currency = currency)\n",
    "            ib.qualifyContracts(contract)\n",
    "            df_temp = get_data(contract, history, freq, side)\n",
    "            latest_tick = df_temp.iloc[-1]\n",
    "            live_data[ticker_ADR] = latest_tick['close'] # NEED TO MULTIPLY BY ADR RATIO\n",
    "            \n",
    "            \n",
    "            contract = Contract(symbol = ticker_underlying, secType = \"STK\", exchange = exchange, currency = currency)\n",
    "            ib.qualifyContracts(contract)\n",
    "            df_temp = get_data(contract, history, freq, side)\n",
    "            latest_tick = df_temp.iloc[-1]\n",
    "            if country == \"Australia\":\n",
    "                live_data[ticker_ADR] = latest_tick['close'] * live_data[\"AUD.USD\"] # NEED TO MULTIPLY BY ADR RATIO\n",
    "            elif country == \"Japan\":\n",
    "                live_data[ticker_ADR] = latest_tick['close'] * live_data[\"JPY.USD\"] # NEED TO MULTIPLY BY ADR RATIO\n",
    "            elif country == \"HK\":\n",
    "                live_data[ticker_ADR] = latest_tick['close'] * live_data[\"HKD.USD\"] # NEED TO MULTIPLY BY ADR RATIO\n",
    "        \n",
    "    \n",
    "    \n",
    "def intraday_trader(HK, AUS, JPN, US):\n",
    "    if HK:\n",
    "        pairs = country_info[\"HK\"][\"Pairs\"]\n",
    "        for ticker_ADR, ticker_underlying in pairs:\n",
    "            # check Z Score of pair\n",
    "            \n",
    "            if (#z score is exit#){\n",
    "                \n",
    "                }\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize_forex()\n",
    "\n",
    "# update date\n",
    "while True:\n",
    "    # keep track of what day it is\n",
    "    today = datetime.date() # ideally the algorithm starts at 8am in the morning\n",
    "    \n",
    "    # keep track of how many times we pull data for calibration\n",
    "    bef_us_pull = False\n",
    "    bef_us_zscore = False\n",
    "    bef_asia_pull = False\n",
    "    bef_jpn_zscore = False\n",
    "    bef_aus_zscore = False\n",
    "    bef_hk_zscore = False\n",
    "    \n",
    "    # Various Open and Close hours for various markets\n",
    "    \n",
    "    US_open = US_opening(today)\n",
    "    US_close = US_closing(today)\n",
    "    HK_open = HK_opening(today + timedelta(days = 1))\n",
    "    HK_close = HK_closing(today + timedelta(days = 1))\n",
    "    JPN_open = JPN_opening(today + timedelta(days = 1))\n",
    "    JPN_close = JPN_closing(today + timedelta(days = 1))\n",
    "    AUS_open = AUS_opening(today + timedelta(days = 1))\n",
    "    AUS_close = AUS_closing(today + timedelta(days = 1))\n",
    "    \n",
    "    # Keep track if pair is open\n",
    "    \n",
    "    while now < US_close and now < HK_close and now < JPN_close and now < AUS_close:\n",
    "        HK_trading = False\n",
    "        AUS_trading = False\n",
    "        US_trading = False\n",
    "        JPN_trading = False\n",
    "        '''\n",
    "        US Market\n",
    "        '''\n",
    "        # Before US Market Open pull historical data\n",
    "        if not bef_us_pull and now > US_open - timedelta(hours = 1):\n",
    "            bef_us_pull = True\n",
    "            pull_asian_close()\n",
    "            pull_forex_data()\n",
    "            \n",
    "        \n",
    "        # Right before US Market Open for Z Score\n",
    "        if not bef_us_zscore and now > US_open - timedelta(minutes = 4):\n",
    "            bef_us_zscore = True\n",
    "            pull_forex_data()\n",
    "            # Calculate Z score \n",
    "            # make trading decision\n",
    "            # convert_price_asian_close()\n",
    "            \n",
    "        if US_open < now and now < US_close:\n",
    "            # Pull minute data to check whether to liquidate positions\n",
    "            US_trading = True\n",
    "            pull_live_data()\n",
    "            intraday_trader(HK_trading, AUS_trading, JPN_trading, US_trading)\n",
    "            \n",
    "        if US_close - timedelta(minutes = 10) < now and now < US_close:\n",
    "            # check pending limit orders and liquidate\n",
    "                        \n",
    "        '''\n",
    "        Asian Markets\n",
    "        '''\n",
    "        \n",
    "        # before asian markets open, pull us market close\n",
    "        if not bef_asia_pull and now > US_close + timedelta(hours = 1):\n",
    "            bef_asia_pull = True\n",
    "            pull_us_close()\n",
    "\n",
    "\n",
    "        \n",
    "        # before Hong Kong market open, pull forex to calculate Z score\n",
    "        if not bef_hk_zscore and now > HK_open - timedelta(minutes = 4):\n",
    "            bef_hk_zscore = True\n",
    "            pull_forex_data()\n",
    "            # convert_price_asian_close()\n",
    "            # calculate Z score and make decision on trade and size\n",
    "        \n",
    "        # check on Hong Kong Stocks\n",
    "        if HK_open < now and now < HK_close:\n",
    "            HK_trading = True\n",
    "            \n",
    "            # Pull minute data to check whether to liquidate positions\n",
    "            \n",
    "        if HK_close - timedelta(minutes = 10) < now and now < HK_close:\n",
    "            # Check pending limit orders and cancel\n",
    "        \n",
    "        # before Japan market open, pull forex to calculate Z score\n",
    "        if not bef_jpn_zscore and now > JPN_opening(today) - timedelta(minutes = 4):\n",
    "            bef_JPN_zscore = True\n",
    "            pull_forex_data()\n",
    "            # convert_price_asian_close()\n",
    "            # calculate Z score\n",
    "            # make decision on trade and size\n",
    "        \n",
    "        # check on Japan stocks\n",
    "        if JPN_open < now and now < JPN_close:\n",
    "            # Pull minute data to check whether to liquidate positions\n",
    "            JPN_trading = True\n",
    "            \n",
    "        if JPN_close - timedelta(minutes = 10) < now and now < JPN_close:\n",
    "            # Check pending limit orders\n",
    "            \n",
    "        # before Australia market open, pull forex to calculate Z score            \n",
    "        if not bef_aus_zscore and now > AUS_opening(today) - timedelta(minutes = 4):\n",
    "            bef_aus_zscore = True\n",
    "            pull_forex_data()\n",
    "            # convert_price_asian_close()\n",
    "        \n",
    "        # check on Australian Stocks\n",
    "        if AUS_open < now and now < AUS_close:\n",
    "            # Pull minute data to check whether to liquidate positions\n",
    "            AUS_trading = True\n",
    "            \n",
    "        if AUS_open - timedelta(minutes = 10) < now and now < AUS_close:\n",
    "            # Check pending limit orders         \n",
    "\n",
    "        ib.sleep(120) # Loop every two minutes\n",
    "        now = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Contract(secType='STK', conId=13905840, symbol='7751', exchange='TSEJ', primaryExchange='TSEJ', currency='JPY', localSymbol='7751.T', tradingClass='7751')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

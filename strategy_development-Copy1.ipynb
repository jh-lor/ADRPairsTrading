{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from ib_insync import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import coint, adfuller\n",
    "from statsmodels import regression,stats\n",
    "import math\n",
    "import datetime \n",
    "import statsmodels.formula.api as smf \n",
    "from datetime import date, time, datetime, timedelta\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from collections import defaultdict\n",
    "\n",
    "mypath = 'eric_jh_data/'\n",
    "countries = ['Australia', 'Japan', 'China']\n",
    "adr_dict = {}\n",
    "return_dict = defaultdict(list)\n",
    "fx_dict = {'Australia':('eric_jh_data/Forex/AUD_USD.csv',0),\n",
    "           'Japan':('eric_jh_data/Forex/USD_JPY.csv',1),\n",
    "           'China':('eric_jh_data/Forex/USD_HKD.csv',1)}\n",
    "for country in countries:\n",
    "    countrypath = mypath + country\n",
    "    adr_names =  [f for f in listdir(countrypath) if not isfile(join(countrypath, f))] #grab all adr names of the country\n",
    "    adr_dict[country] = adr_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9968998155966732\n",
      "no data for underlying data of PLL_PLL from Australia\n",
      "None\n",
      "0.0016854872904929566\n",
      "no data for underlying data of ATHE_ATH from Australia\n",
      "None\n",
      "no data for underlying data of IMMP_IMM from Australia\n",
      "None\n",
      "0.9999189577547546\n",
      "no data for underlying data of KZIA_KZA from Australia\n",
      "None\n",
      "0.19828354680499435\n",
      "0.025514770969943097\n",
      "0.999506635151424\n",
      "0.9998565489650568\n",
      "5.00274185269611\n",
      "0.19973421064724692\n",
      "5.0009639745568455\n",
      "2.0007728095562984\n",
      "1.0005206886504754\n",
      "1.000465778069457\n",
      "0.9991914463657956\n",
      "0.4997965869827934\n",
      "0.019984795881583636\n",
      "0.07702157139299512\n",
      "0.2000834607772626\n",
      "0.020005056415712753\n",
      "0.009995426701454152\n",
      "0.009994709455041776\n",
      "0.04004598282939929\n",
      "0.025057346730456967\n",
      "0.009995608807595648\n"
     ]
    }
   ],
   "source": [
    "for country in countries:\n",
    "    countrypath = mypath + country\n",
    "    adr_names =  [f for f in listdir(countrypath) if not isfile(join(countrypath, f))] #grab all adr names of the country\n",
    "    adr_dict[country] = adr_names\n",
    "    \n",
    "    for adr in adr_names:\n",
    "        print(data_processing(country, adr, fx_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ACH_2600',\n",
       " 'BGNE_6160',\n",
       " 'CEA_670',\n",
       " 'HNP_902',\n",
       " 'LFC_2628',\n",
       " 'PTR_857',\n",
       " 'SHI_338',\n",
       " 'SNP_386',\n",
       " 'ZNH_1055']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(adr_dict[\"China\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>adr_open</th>\n",
       "      <th>adr_close</th>\n",
       "      <th>stock_open</th>\n",
       "      <th>stock_close</th>\n",
       "      <th>fx_open</th>\n",
       "      <th>fx_close</th>\n",
       "      <th>stock_open_usd</th>\n",
       "      <th>stock_close_usd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-04-13</td>\n",
       "      <td>39.65</td>\n",
       "      <td>38.93</td>\n",
       "      <td>5.91</td>\n",
       "      <td>5.91</td>\n",
       "      <td>7.75006</td>\n",
       "      <td>7.75013</td>\n",
       "      <td>38.128737</td>\n",
       "      <td>38.128393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-04-14</td>\n",
       "      <td>38.00</td>\n",
       "      <td>37.63</td>\n",
       "      <td>5.91</td>\n",
       "      <td>5.91</td>\n",
       "      <td>7.75077</td>\n",
       "      <td>7.75084</td>\n",
       "      <td>38.125244</td>\n",
       "      <td>38.124900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-04-15</td>\n",
       "      <td>37.35</td>\n",
       "      <td>37.40</td>\n",
       "      <td>5.91</td>\n",
       "      <td>5.91</td>\n",
       "      <td>7.75150</td>\n",
       "      <td>7.75159</td>\n",
       "      <td>38.121654</td>\n",
       "      <td>38.121211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-04-16</td>\n",
       "      <td>37.09</td>\n",
       "      <td>37.61</td>\n",
       "      <td>5.91</td>\n",
       "      <td>5.91</td>\n",
       "      <td>7.75151</td>\n",
       "      <td>7.75163</td>\n",
       "      <td>38.121605</td>\n",
       "      <td>38.121015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-04-17</td>\n",
       "      <td>36.96</td>\n",
       "      <td>37.45</td>\n",
       "      <td>5.91</td>\n",
       "      <td>5.91</td>\n",
       "      <td>7.75156</td>\n",
       "      <td>7.75163</td>\n",
       "      <td>38.121359</td>\n",
       "      <td>38.121015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>23.96</td>\n",
       "      <td>24.06</td>\n",
       "      <td>3.70</td>\n",
       "      <td>3.71</td>\n",
       "      <td>7.77221</td>\n",
       "      <td>7.77226</td>\n",
       "      <td>23.802754</td>\n",
       "      <td>23.866932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>2021-03-30</td>\n",
       "      <td>23.78</td>\n",
       "      <td>23.83</td>\n",
       "      <td>3.71</td>\n",
       "      <td>3.74</td>\n",
       "      <td>7.77439</td>\n",
       "      <td>7.77445</td>\n",
       "      <td>23.860393</td>\n",
       "      <td>24.053148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>2021-03-31</td>\n",
       "      <td>23.80</td>\n",
       "      <td>23.40</td>\n",
       "      <td>3.71</td>\n",
       "      <td>3.66</td>\n",
       "      <td>7.77445</td>\n",
       "      <td>7.77451</td>\n",
       "      <td>23.860209</td>\n",
       "      <td>23.538461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>23.48</td>\n",
       "      <td>23.56</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.65</td>\n",
       "      <td>7.77517</td>\n",
       "      <td>7.77521</td>\n",
       "      <td>23.600770</td>\n",
       "      <td>23.472035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440</th>\n",
       "      <td>2021-04-07</td>\n",
       "      <td>23.60</td>\n",
       "      <td>23.52</td>\n",
       "      <td>3.68</td>\n",
       "      <td>3.70</td>\n",
       "      <td>7.78095</td>\n",
       "      <td>7.78099</td>\n",
       "      <td>23.647498</td>\n",
       "      <td>23.775895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1441 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  adr_open  adr_close  stock_open  stock_close  fx_open  \\\n",
       "0     2015-04-13     39.65      38.93        5.91         5.91  7.75006   \n",
       "1     2015-04-14     38.00      37.63        5.91         5.91  7.75077   \n",
       "2     2015-04-15     37.35      37.40        5.91         5.91  7.75150   \n",
       "3     2015-04-16     37.09      37.61        5.91         5.91  7.75151   \n",
       "4     2015-04-17     36.96      37.45        5.91         5.91  7.75156   \n",
       "...          ...       ...        ...         ...          ...      ...   \n",
       "1436  2021-03-29     23.96      24.06        3.70         3.71  7.77221   \n",
       "1437  2021-03-30     23.78      23.83        3.71         3.74  7.77439   \n",
       "1438  2021-03-31     23.80      23.40        3.71         3.66  7.77445   \n",
       "1439  2021-04-01     23.48      23.56        3.67         3.65  7.77517   \n",
       "1440  2021-04-07     23.60      23.52        3.68         3.70  7.78095   \n",
       "\n",
       "      fx_close  stock_open_usd  stock_close_usd  \n",
       "0      7.75013       38.128737        38.128393  \n",
       "1      7.75084       38.125244        38.124900  \n",
       "2      7.75159       38.121654        38.121211  \n",
       "3      7.75163       38.121605        38.121015  \n",
       "4      7.75163       38.121359        38.121015  \n",
       "...        ...             ...              ...  \n",
       "1436   7.77226       23.802754        23.866932  \n",
       "1437   7.77445       23.860393        24.053148  \n",
       "1438   7.77451       23.860209        23.538461  \n",
       "1439   7.77521       23.600770        23.472035  \n",
       "1440   7.78099       23.647498        23.775895  \n",
       "\n",
       "[1441 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_processing(\"China\", 'CEA_670', fx_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = \"Australia\"\n",
    "adr = 'WBK_WBC'\n",
    "adr_path = f'eric_jh_data/{country}/{adr}/adr.csv'\n",
    "stock_path =  f'eric_jh_data/{country}/{adr}/underlying.csv'\n",
    "fx_path = fx_dict[country][0]\n",
    "fx_type =  fx_dict[country][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "adr_df = pd.read_csv(adr_path, index_col = 0).rename(columns = {'close':'adr_close', 'open':'adr_open'})\n",
    "stock_df = pd.read_csv(stock_path, index_col = 0).rename(columns = {'close':'stock_close', 'open':'stock_open'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "fx_df = pd.read_csv(fx_path, index_col = 0).rename(columns = {'close':'fx_close', 'open':'fx_open'})\n",
    "merged_df = pd.merge(adr_df.loc[:,['date', 'adr_open','adr_close']], stock_df.loc[:,['date', 'stock_open','stock_close']])\n",
    "merged_df = pd.merge(merged_df, fx_df.loc[:,['date', 'fx_open','fx_close']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fx_type == 1:\n",
    "    merged_df['stock_open_usd'] = merged_df['stock_open']/merged_df['fx_open']\n",
    "    merged_df['stock_close_usd'] = merged_df['stock_close']/merged_df['fx_close']\n",
    "else:\n",
    "    merged_df['stock_open_usd'] = merged_df['stock_open']*merged_df['fx_open']\n",
    "    merged_df['stock_close_usd'] = merged_df['stock_close']*merged_df['fx_close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio =round(merged_df.loc[1,'stock_close_usd']/merged_df.loc[1,'adr_open'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999189577547546"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(merged_df.loc[:,'stock_close_usd']/merged_df.loc[:,'adr_open'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.996073642384106"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.loc[1,'stock_close_usd']/merged_df.loc[1,'adr_open']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adr_path = f'eric_jh_data/{country}/{adr}/adr.csv'\n",
    "stock_path =  f'eric_jh_data/{country}/{adr}/underlying.csv'\n",
    "fx_path = fx_dict[country][0]\n",
    "fx_type =  fx_dict[country][1]\n",
    "try:\n",
    "    adr_df = pd.read_csv(adr_path, index_col = 0).rename(columns = {'close':'adr_close', 'open':'adr_open'})\n",
    "except:\n",
    "    print(f\"no data for ADR data of {adr} from {country}\")\n",
    "    return None\n",
    "try:\n",
    "    stock_df = pd.read_csv(stock_path, index_col = 0).rename(columns = {'close':'stock_close', 'open':'stock_open'})\n",
    "except:\n",
    "    print(f\"no data for underlying data of {adr} from {country}\")\n",
    "    return None\n",
    "fx_df = pd.read_csv(fx_path, index_col = 0).rename(columns = {'close':'fx_close', 'open':'fx_open'})\n",
    "\n",
    "merged_df = pd.merge(adr_df.loc[:,['date', 'adr_open','adr_close']], stock_df.loc[:,['date', 'stock_open','stock_close']])\n",
    "merged_df = pd.merge(merged_df, fx_df.loc[:,['date', 'fx_open','fx_close']])\n",
    "\n",
    "if fx_type == 1:\n",
    "    merged_df['stock_open_usd'] = merged_df['stock_open']/merged_df['fx_open']\n",
    "    merged_df['stock_close_usd'] = merged_df['stock_close']/merged_df['fx_close']\n",
    "else:\n",
    "    merged_df['stock_open_usd'] = merged_df['stock_open']*merged_df['fx_open']\n",
    "    merged_df['stock_close_usd'] = merged_df['stock_close']*merged_df['fx_close']\n",
    "\n",
    "ratio =round(merged_df.loc[1,'stock_close_usd']/merged_df.loc[1,'adr_open'])\n",
    "if ratio >= 1:\n",
    "    merged_df['adr_open'] = merged_df['adr_open']*ratio\n",
    "    merged_df['adr_close'] = merged_df['adr_close']*ratio\n",
    "else:\n",
    "    ratio = round(merged_df.loc[1,'adr_open']/merged_df.loc[1,'stock_close_usd'])\n",
    "    merged_df['stock_open_usd'] = merged_df['stock_open_usd']*ratio\n",
    "    merged_df['stock_close_usd'] = merged_df['stock_close_usd']*ratio\n",
    "\n",
    "return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no underlying data for Australia, PLL_PLL\n",
      "There is no underlying data for Australia, ATHE_ATH\n",
      "There is no underlying data for Australia, IMMP_IMM\n",
      "There is no underlying data for Australia, KZIA_KZA\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from collections import defaultdict\n",
    "\n",
    "mypath = 'eric_jh_data/'\n",
    "countries = ['Australia', 'Japan', 'China']\n",
    "adr_dict = {}\n",
    "return_dict = defaultdict(list)\n",
    "fx_dict = {'Australia':('eric_jh_data/Forex/AUD_USD.csv',0),\n",
    "           'Japan':('eric_jh_data/Forex/USD_JPY.csv',1),\n",
    "           'China':('eric_jh_data/Forex/USD_HKD.csv',1)}\n",
    "for country in countries:\n",
    "    countrypath = mypath + country\n",
    "    adr_names =  [f for f in listdir(countrypath) if not isfile(join(countrypath, f))] #grab all adr names of the country\n",
    "    adr_dict[country] = adr_names\n",
    "    \n",
    "    for adr in adr_names:\n",
    "        merged_df = data_processing(country, adr, fx_dict)\n",
    "        if isinstance(merged_df, pd.core.frame.DataFrame):\n",
    "            ret, trade_records = pairs_trade(merged_df)\n",
    "            return_dict[country].append([adr, ret])\n",
    "            logs = [f'The return of ADR_underlying pairs trading for {adr} from {country} is {ret*100}%\\n']\n",
    "            logs = logs + trade_records \n",
    "            \n",
    "            \n",
    "            fname = f'eric_jh_data/{country}/{adr}/logs.txt'\n",
    "            f = open(fname, 'w')\n",
    "            f.writelines(logs)\n",
    "            f.close()\n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing(country, adr, fx_dict):\n",
    "    adr_path = f'eric_jh_data/{country}/{adr}/adr.csv'\n",
    "    stock_path =  f'eric_jh_data/{country}/{adr}/underlying.csv'\n",
    "    fx_path = fx_dict[country][0]\n",
    "    fx_type =  fx_dict[country][1]\n",
    "    try:\n",
    "        adr_df = pd.read_csv(adr_path, index_col = 0).rename(columns = {'close':'adr_close', 'open':'adr_open'})\n",
    "    except:\n",
    "        print(f\"no data for ADR data of {adr} from {country}\")\n",
    "        return None\n",
    "    try:\n",
    "        stock_df = pd.read_csv(stock_path, index_col = 0).rename(columns = {'close':'stock_close', 'open':'stock_open'})\n",
    "    except:\n",
    "        print(f\"no data for underlying data of {adr} from {country}\")\n",
    "        return None\n",
    "    fx_df = pd.read_csv(fx_path, index_col = 0).rename(columns = {'close':'fx_close', 'open':'fx_open'})\n",
    "\n",
    "    merged_df = pd.merge(adr_df.loc[:,['date', 'adr_open','adr_close']], stock_df.loc[:,['date', 'stock_open','stock_close']])\n",
    "    merged_df = pd.merge(merged_df, fx_df.loc[:,['date', 'fx_open','fx_close']])\n",
    "\n",
    "    if fx_type == 1:\n",
    "        merged_df['stock_open_usd'] = merged_df['stock_open']/merged_df['fx_open']\n",
    "        merged_df['stock_close_usd'] = merged_df['stock_close']/merged_df['fx_close']\n",
    "    else:\n",
    "        merged_df['stock_open_usd'] = merged_df['stock_open']*merged_df['fx_open']\n",
    "        merged_df['stock_close_usd'] = merged_df['stock_close']*merged_df['fx_close']\n",
    "\n",
    "    ratio = np.mean(merged_df['stock_close_usd']/merged_df['adr_open'])\n",
    "    return ratio\n",
    "    if ratio >= 1:\n",
    "        merged_df['adr_open'] = merged_df['adr_open']*ratio\n",
    "        merged_df['adr_close'] = merged_df['adr_close']*ratio\n",
    "    else:\n",
    "        ratio = round(merged_df.loc[1,'adr_open']/merged_df.loc[1,'stock_close_usd'])\n",
    "        merged_df['stock_open_usd'] = merged_df['stock_open_usd']*ratio\n",
    "        merged_df['stock_close_usd'] = merged_df['stock_close_usd']*ratio\n",
    "        \n",
    "    return merged_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because 1 ADR is not necessarily 1 Underlying, we find the ratio to convert the two..\n",
    "ratio =round(merged_df.loc[1,'stock_close_usd']/merged_df.loc[1,'adr_open'])\n",
    "if ratio >= 1:\n",
    "    merged_df['adr_open'] = merged_df['adr_open']*ratio\n",
    "    merged_df['adr_close'] = merged_df['adr_close']*ratio\n",
    "else:\n",
    "    ratio = round(merged_df.loc[1,'adr_open']/merged_df.loc[1,'stock_close_usd'])\n",
    "    merged_df['stock_open_usd'] = merged_df['stock_open_usd']*ratio\n",
    "    merged_df['stock_close_usd'] = merged_df['stock_close_usd']*ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>adr_open</th>\n",
       "      <th>adr_close</th>\n",
       "      <th>stock_open</th>\n",
       "      <th>stock_close</th>\n",
       "      <th>fx_open</th>\n",
       "      <th>fx_close</th>\n",
       "      <th>stock_open_usd</th>\n",
       "      <th>stock_close_usd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-04-13</td>\n",
       "      <td>30.36</td>\n",
       "      <td>30.13</td>\n",
       "      <td>39.99</td>\n",
       "      <td>39.77</td>\n",
       "      <td>0.76009</td>\n",
       "      <td>0.76013</td>\n",
       "      <td>30.395999</td>\n",
       "      <td>30.230370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-04-14</td>\n",
       "      <td>30.20</td>\n",
       "      <td>30.36</td>\n",
       "      <td>39.70</td>\n",
       "      <td>39.56</td>\n",
       "      <td>0.76036</td>\n",
       "      <td>0.76040</td>\n",
       "      <td>30.186292</td>\n",
       "      <td>30.081424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-04-15</td>\n",
       "      <td>29.93</td>\n",
       "      <td>30.09</td>\n",
       "      <td>39.40</td>\n",
       "      <td>38.92</td>\n",
       "      <td>0.76161</td>\n",
       "      <td>0.76165</td>\n",
       "      <td>30.007434</td>\n",
       "      <td>29.643418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-04-16</td>\n",
       "      <td>30.48</td>\n",
       "      <td>30.60</td>\n",
       "      <td>39.34</td>\n",
       "      <td>39.27</td>\n",
       "      <td>0.77584</td>\n",
       "      <td>0.77588</td>\n",
       "      <td>30.521546</td>\n",
       "      <td>30.468808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-04-17</td>\n",
       "      <td>30.28</td>\n",
       "      <td>30.07</td>\n",
       "      <td>39.33</td>\n",
       "      <td>38.90</td>\n",
       "      <td>0.77896</td>\n",
       "      <td>0.77901</td>\n",
       "      <td>30.636497</td>\n",
       "      <td>30.303489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>2021-03-30</td>\n",
       "      <td>18.55</td>\n",
       "      <td>18.61</td>\n",
       "      <td>24.45</td>\n",
       "      <td>24.36</td>\n",
       "      <td>0.76240</td>\n",
       "      <td>0.76242</td>\n",
       "      <td>18.640680</td>\n",
       "      <td>18.572551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476</th>\n",
       "      <td>2021-03-31</td>\n",
       "      <td>18.61</td>\n",
       "      <td>18.56</td>\n",
       "      <td>24.45</td>\n",
       "      <td>24.41</td>\n",
       "      <td>0.76080</td>\n",
       "      <td>0.76082</td>\n",
       "      <td>18.601560</td>\n",
       "      <td>18.571616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>18.61</td>\n",
       "      <td>18.73</td>\n",
       "      <td>24.42</td>\n",
       "      <td>24.54</td>\n",
       "      <td>0.75840</td>\n",
       "      <td>0.75841</td>\n",
       "      <td>18.520128</td>\n",
       "      <td>18.611381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>2021-04-06</td>\n",
       "      <td>18.82</td>\n",
       "      <td>18.84</td>\n",
       "      <td>24.75</td>\n",
       "      <td>24.70</td>\n",
       "      <td>0.76446</td>\n",
       "      <td>0.76449</td>\n",
       "      <td>18.920385</td>\n",
       "      <td>18.882903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>2021-04-07</td>\n",
       "      <td>18.87</td>\n",
       "      <td>18.92</td>\n",
       "      <td>24.71</td>\n",
       "      <td>24.73</td>\n",
       "      <td>0.76456</td>\n",
       "      <td>0.76459</td>\n",
       "      <td>18.892278</td>\n",
       "      <td>18.908311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1480 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  adr_open  adr_close  stock_open  stock_close  fx_open  \\\n",
       "0     2015-04-13     30.36      30.13       39.99        39.77  0.76009   \n",
       "1     2015-04-14     30.20      30.36       39.70        39.56  0.76036   \n",
       "2     2015-04-15     29.93      30.09       39.40        38.92  0.76161   \n",
       "3     2015-04-16     30.48      30.60       39.34        39.27  0.77584   \n",
       "4     2015-04-17     30.28      30.07       39.33        38.90  0.77896   \n",
       "...          ...       ...        ...         ...          ...      ...   \n",
       "1475  2021-03-30     18.55      18.61       24.45        24.36  0.76240   \n",
       "1476  2021-03-31     18.61      18.56       24.45        24.41  0.76080   \n",
       "1477  2021-04-01     18.61      18.73       24.42        24.54  0.75840   \n",
       "1478  2021-04-06     18.82      18.84       24.75        24.70  0.76446   \n",
       "1479  2021-04-07     18.87      18.92       24.71        24.73  0.76456   \n",
       "\n",
       "      fx_close  stock_open_usd  stock_close_usd  \n",
       "0      0.76013       30.395999        30.230370  \n",
       "1      0.76040       30.186292        30.081424  \n",
       "2      0.76165       30.007434        29.643418  \n",
       "3      0.77588       30.521546        30.468808  \n",
       "4      0.77901       30.636497        30.303489  \n",
       "...        ...             ...              ...  \n",
       "1475   0.76242       18.640680        18.572551  \n",
       "1476   0.76082       18.601560        18.571616  \n",
       "1477   0.75841       18.520128        18.611381  \n",
       "1478   0.76449       18.920385        18.882903  \n",
       "1479   0.76459       18.892278        18.908311  \n",
       "\n",
       "[1480 rows x 9 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-8050d81b6045>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m\"2016\"\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mmerged_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"date\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;34m\"2021\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1477\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m         raise ValueError(\n\u001b[0;32m-> 1479\u001b[0;31m             \u001b[0;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1480\u001b[0m             \u001b[0;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "\"2016\" <= merged_df[\"date\"] <= \"2021\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ['a\\n','b\\n','c\\n']\n",
    "fname = 'text.txt'\n",
    "f = open(fname, \"w\")\n",
    "f.writelines(test)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Naive strategy for testing on the SONY adr and stock pair\n",
    "To open a position, we check the CLOSE price of adr, compared it to CLOSE px of \n",
    "stock. We buy the stock on the next trading next OPEN for Asian market\n",
    "\n",
    "To close a position,  we check the CLOSE price of adr, compared it to CLOSE px of \n",
    "stock. We sell the stock on the next trading next OPEN for Asian market\n",
    "\"\"\"\n",
    "def pairs_trade(merged_df, lookback = 100, cash = 100000):\n",
    "\n",
    "    starting_cash = cash\n",
    "    stock_pos, adr_pos = 0, 0\n",
    "    diff_record = deque(maxlen = lookback)\n",
    "    trade_records = []\n",
    "\n",
    "\n",
    "    for index, row in merged_df.iterrows():\n",
    "        # check if there is a px diff between close and stock_close effective\n",
    "        # If index < lookback, we do not place any trade\n",
    "        if index < lookback:\n",
    "            diff_record.append(row['adr_close'] - row['stock_close_usd'])\n",
    "            pass\n",
    "\n",
    "        # If we have passed the initial lookback window\n",
    "        # enter the position if diff is significant\n",
    "        if row['adr_close'] - row['stock_close_usd'] > np.array(diff_record).mean() + np.array(diff_record).std():\n",
    "            if stock_pos == 0 and adr_pos == 0:\n",
    "                quantity = min(int(0.5*cash/row['adr_close']),int(0.5*cash/row['stock_close_usd']))\n",
    "                if index+1 < len(merged_df):\n",
    "                    adr_pos -= quantity\n",
    "                    cash += quantity*row['adr_close']\n",
    "\n",
    "                    stock_px = merged_df.loc[index+1,'stock_open_usd'] # The actual px we get to trade is on the next day for asian market\n",
    "                    cash -= stock_px*quantity\n",
    "                    stock_pos += quantity\n",
    "                    trade_records.append(\"Opening positions:\\n\")\n",
    "                    trade_records.append(f\"We sold the {quantity} shares of ADR at the price of {row['adr_close']} on {row['date']}\\n\")\n",
    "                    trade_records.append(f\"We bought the {quantity} shares of underlying stock at the price of {stock_px} USD ({merged_df.loc[index+1,'stock_open']} Japanese dollars) on {merged_df.loc[index+1,'date']}\\n\")\n",
    "\n",
    "\n",
    "        # When do we exit the position?\n",
    "        elif row['adr_close'] - row['stock_close_usd'] < np.array(diff_record).mean():\n",
    "            if stock_pos > 0 and adr_pos < 0 : # If we have positions in the stocks, we liquidate the position\n",
    "                if index+1 < len(merged_df):\n",
    "                \n",
    "                    cash -= abs(adr_pos)*row['adr_close']\n",
    "                    cash += stock_pos*merged_df.loc[index+1,'stock_open_usd']\n",
    "                    \n",
    "                    trade_records.append(\"Closing positions:\\n\")\n",
    "                    trade_records.append(f\"We bought the {stock_pos} shares of ADR at the price of {row['adr_close']} on {row['date']}\\n\")\n",
    "                    trade_records.append(f\"We sold the {stock_pos} shares of underlying stock at the price of {merged_df.loc[index+1,'stock_open_usd']} USD ({merged_df.loc[index+1,'stock_open']} Japanese dollars) on {merged_df.loc[index+1,'date']}\\n\")\n",
    "                    stock_pos, adr_pos = 0, 0\n",
    "        diff_record.append(row['adr_close'] - row['stock_close_usd'])\n",
    "    final_val = cash + adr_pos*merged_df.loc[len(merged_df) - 1, 'adr_close'] + stock_pos*merged_df.loc[len(merged_df) - 1, 'stock_close_usd'] \n",
    "    ret = (final_val - starting_cash)/starting_cash\n",
    "    \n",
    "    \n",
    "    return ret, trade_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110513.74525800598"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Old code snippets\n",
    "\n",
    "# Grab the csv data for the stocks\n",
    "adr_path = 'eric_jh_data/Japan/IX_8591/adr.csv'\n",
    "stock_path = 'eric_jh_data/Japan/IX_8591/underlying.csv'\n",
    "fx_path = 'eric_jh_data/Forex/USD_JPY.csv'\n",
    "adr_df = pd.read_csv(adr_path, index_col = 0).rename(columns = {'close':'adr_close', 'open':'adr_open'})\n",
    "stock_df = pd.read_csv(stock_path, index_col = 0).rename(columns = {'close':'stock_close', 'open':'stock_open'})\n",
    "fx_df = pd.read_csv(fx_path, index_col = 0).rename(columns = {'close':'fx_close', 'open':'fx_open'})\n",
    "\n",
    "# Find the ratio between adr and stock:\n",
    "\n",
    "\n",
    "merged_df = pd.merge(adr_df.loc[:,['date', 'adr_open','adr_close']], stock_df.loc[:,['date', 'stock_open','stock_close']])\n",
    "merged_df = pd.merge(merged_df, fx_df.loc[:,['date', 'fx_open','fx_close']])\n",
    "merged_df['stock_open_usd'] = merged_df['stock_open']/merged_df['fx_open']\n",
    "merged_df['stock_close_usd'] = merged_df['stock_close']/merged_df['fx_close']\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
